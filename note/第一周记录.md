### 第一周记录

`24/10/14 ~ 24/10/20`

之前明确了课题要做的内容，就是将机器学习和水平集方法结合，训练一个模型，在给定网格和控制点的情况下，预测符合条件的曲线。

但是对于这个课题有哪些关键的问题，每个问题要如何解决，还没有清晰的认识。

由于课题是将机器学习（DL）和水平集方法（LSM）结合，用LSM隐式表示曲线，求解更新水平集函数（LSF），涉及到DL处理mesh数据、隐式方法表示曲线、DL求解PDE、DL与LSM等方面。每个方面都需要看一定数量的论文来了解。这也是我这周，包括接下来的两周的主要任务。

**主要任务：**看以上几个方面的论文，来理清课题有哪些关键的问题，以及这些问题目前的解决方法和对应的优缺点。



#### 本周工作

1. 仔细阅读老师发的几篇有关DL和LSM结合的文章并整理。
2. 阅读两篇有关3D重建的文章。
3. 了解Nerf的思想。
4. 整理之前看过的有关DL解PDE、DL预测测地路径的文章。



##### 阅读DL+LSM的4篇文章

本周的主要时间用来读这几篇文章，但是基本每篇文章都存在不理解的地方。

###### 论文1

`Learning high-order geometric flow based on the level set method`

这篇文章提出了一个新的框架，来求解高阶几何流。然后用提出的框架求解两个GPDE，并用实验验证了该框架在不同的模型上的效果。

作者将求解PDE问题看作PDE约束的优化问题，结合PINN和LSM，求解高阶的GPDE（几何偏微分方程）

主要思路是将高阶的GPDE分解为多个中间过程子式，然后将GPDE以及各个子式和初值、边界值都放入损失函数中，通过有限差分来计算梯度并更新LSM。

**问题：**

1. 对于各个子式的损失项公式不理解，github有非官方的代码，这部分的实现和论文中不一样，代码没有看懂。
2. 对于论文中求解的两个GPDE不了解。

###### 论文2

`Deep Level Sets for Salient Object Detection`

这篇论文用一系列卷积层初始化显著图，然后在超像素级别对其进行细化。 水平集损失函数用于帮助学习二进制分割图。

在文章中，LSM只是起到一个辅助的作用，作为损失函数对训练过的VGG模型进行微调。输入是二维图像，水平集图直接通过变换后的二值图得到，没有涉及到水平集函数的演变。

![image-20241014145556029](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241014145556029.png)

将图片输入VGG16，通过BCE loss进行显著性目标检测， 得到检测结果的二值图。将二值图的值水平移动到[-0.5,0.5]，作为初始的水平集图。

之后再次训练VGG16，通过水平集函数来对水平集图进行约束，帮助VGG16学习显著目标的边界。最后使用Heaviside 函数将水平集图转换为二值图输出。



问题1：不理解水平集损失函数中的两项。（强制显著性图在显著区域内部和外部均一致，意思可以理解，但是公式不是很理解）

问题2：作者给出了水平集损失的导数，不确定这个导数在训练中是否使用？（训练时直接用自动微分求出水平集导数，还是用自动微分求出各个变量的导数，然后再根据手动推出的导数进行水平集的导数）

###### 论文3

`DevelSet: Deep Neural Level Set for Instant Mask Optimization`

这篇文章主要是进行掩膜优化（文章中涉及到光刻相关的知识，这部分内容并没有仔细了解，只对文章中掩膜优化相关的部分进行仔细阅读）

模型由两部分组成：

- 第一部分名为DSN，由ViT作为主干网络，并通过两个分支网络同时优化两个损失函数。
- 第二部分名为DSO，通过CG（共轭梯度法）对DSN输出的水平集图在GPU上进行优化，得到最终的掩码图。

![image-20241015160037204](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241015160037204.png)

关键点：

1. 作者提出CUDA TSDF，用于将掩膜图像转换为水平集图，作为输入。
2. DSN中，LSM作为loss函数，用于约束水平集图，通过ViT得到准优化的水平集图。
3. DSO中，水平集函数的演化方程由光刻领域的一些约束和曲率项组成，并使用共轭梯度法优化水平集图，得到最终结果。（优化过程在GPU上）。

这篇和论文2类似，都是通过LSM损失函数来指导二维的水平集图的生成，只不过这篇文章生成的是准优化图，还有后续的优化模型对水平集图进行进一步优化。

**问题**

1. DSN两个分支的损失函数中的GT值是通过事先训练DSO得到的，但是训练DSO时$m_{\theta}$ 是怎么来的？事先训练DSO时没有使用曲率项？
2. 调制分支，计算损失函数时的$m_{gt}$ 是什么？

###### 论文4

`Deep Level Sets: Implicit Surface Representations for 3D Shape Inference`

作者提出了一个基于水平集函数的损失函数，并设计了一个简单的CNN网络，分别使用水平集loss和以前的基于体素的loss，通过输入的多视角图像重建出3d体素模型，以证明作者提出的水平集loss的优势。

![image-20241020215417405](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241020215417405.png)

输入为多视角图像，通过CNN先升维为64维的特征向量，再降维为三维张量，类似于体素格式，每个位置的值为TSDF值，水平集通过作为损失函数来指导最终体素数据的生成。

所以这篇文章其实也只是用SDF来进行约束，并没有涉及到LSM的演变。



##### 有关3D重建的文章

`DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation`

这篇文章并没有花很多时间去读，只是理解作者的思路。

训练一个可泛化的模型，**将3d模型映射为嵌入向量**，并可以根据嵌入向量和给定坐标来查询sdf值。

可以看[博客](https://zhuanlan.zhihu.com/p/418237767)

##### 了解Nerf

没有看论文，主要通过看博客和视频的方式来了解，只是理解了思路，细节还有很多不懂。



#### 总结

这周虽然只读了DL+LSM的几篇论文，但是结合之前读的一些文章，以及一些博客，整理出了一个大概的思路，我目前要完成的大致分为以下几步：

1. **如何表示mesh上的LSF？**

   - 如何处理mesh格式的输入？

     - 基于图结构的方法，输入为顶点之间的邻接关系，通过邻接矩阵的方式作为输入。**卷积的方法也是使用图卷积的方法来做。**
     - 基于网格结构的方法，输入为顶点坐标(N * 3)，面信息（M * K）[K边形]，特征信息（附加的顶点或面信息）。**卷积的方法会利用网格的内在属性。**

     这两种方式的区别主要是对于卷积的定义不同。

   - 如何在模型中定义LSF？

     - 各顶点的特征向量多一维，用于存LSF标量值
     - 将特征向量通过FC层降维至3维，作为lsm \\ 体素数据
     - 根据输入构建水平集图（二维情况）
     - （Nerf的方式，将一个场景模型的表面存储在神经网络中。缺点是一个模型只能保存一个曲面）

2. **如何训练？**

- 用sdf？用sdf loss做监督（静态）

  在输入的对象（图像\模型）上定义sdf，并设计sdf loss来进行模型训练。训练过程和一般的模型训练过程相同。

- 用lsf？解pde，类似PINN（动态）

  在输入的对象（图像\模型）上定义lsf，将要求解的水平集函数和一些约束条件作为loss，并使用自动微分和手动推导的水平集梯度进行梯度计算，从而更新水平集。

  

#### 下周主要任务

1. 阅读DL解PDE 的有关论文，了解主流的方法及所用的模型。
2. 阅读DL处理mesh数据的有关论文。
3. 弄清这周读论文过程中遇到的问题。
4. 了解Nerf和Gaussisan Splatting

























