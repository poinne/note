#### 思路：

**数据集构造**



模型为GNN+RNN



**输入数据格式：**

mesh数据：$(V,F)$

控制点：$V_{interp}、V_{obs}$

切法向：$list:(a_1,a_2...), a_i = \{v_i,n_i\}$(这里的顶点是插值点还是任意顶点？)

**根据控制点坐标初始化模型上的水平集值：**

在输入模型前，先对模型进行预处理，根据插值点生成初始水平集。

根据插值点，沿模型的edge生成一个圆环，然后使用fast marching 在顶点上构造初始水平集。

**mesh模型在网络中的表示形式：**

网格由$(V,F)$ 对定义，其中$V = \{v_1,v_2,...,\},v_n$是$R^3$中的顶点坐标集合。$F$定义连通性，是三角形网格的顶点三元组。边$E$可以由给定的$(V,F)$对表示。且$V,E,F$都可以与各种特征关联。（主要处理的是顶点的特征）

然后构造顶点的初始向量（包括水平集值和网格内部属性）用于网格卷积。



控制点可以通过输入顶点坐标，切法向输入为指定点归一化的向量（6维）。

**mesh卷积：**

首先，水平集的信号值是定义在网格的顶点上，可以使用mesh的内部属性，如顶点一邻域的三角形的夹角，面积，等结合水平集信号作为初始的顶点向量。

之后对网格进行卷积，上采样，下采样操作进行特征提取。参考meshCNN

**梯度的计算：**

1. 使用GCN来近似离散流形上的微分算子。（GCN在模型训练之前通过mse单独训练）

   $IsoGCN$是对欧式空间中进行的卷积，不能直接在2流形上使用，需要修改$IsoGCN$的卷积操作，使其可以处理网格，参考MeshCNN及其相关文章。

   优点：精度高，速度比有限元快。保证等方差变换，泛化能力强。（对于输入的一些变换，输入不变或等变）可以处理不完整的网格（？）

   缺点：需要将IsoGCN中的卷积操作从二维修改到流形

2. 使用有限差分来进行近似微分算子。

   使用网络来定义可学习的差分算子，来计算梯度和拉普拉斯。参考下面论文：

   `PHYSICS-AWARE DIFFERENCE GRAPH NETWORKS FOR SPARSELY-OBSERVED DYNAMICS`

   差分算子形式是固定的，里面的参数是学习出来的。

3. 使用固定的有限差分：

   

4. 使用自动微分+有限差分：

   参考文章：

   `CAN-PINN: A fast physics-informed neural network based on coupled-automatic–numerical differentiation method`

**水平集的更新：**

1. **使用优化的思想，将各种约束都加入能量函数，通过最小化能量函数，进行水平集更新。**

   将水平集演化看作优化问题，将各种约束作为损失函数：

   损失函数为：$\mathcal{E} = E_{shape} + E_{sdf} + E_{topology}$
   $$
   E_{shape} = w_{interp}E_{interp}(\phi) + w_{obs}E_{obs}(\phi) + w_{smooth}E_{smooth}(\phi) + w_{tan}E_{tan}(\phi)\\
   E_{sdf}(\phi) = \int_M \frac{1}{2}(|\nabla\phi|^2 - 1)^2dM
   $$
   

   用GCN的组合或有限差分求损失函数，使用梯度下降训练网络参数。可以通过RNN来循环表示水平集在每个时间步的值。

   1. 将每个顶点的信号值编码，在RNN的每个循环中，利用GCN或差分得到微分算子，计算损失函数，更新水平集的嵌入表示。在t个时间步后，解码输出。

###### PENN与有限元方法的误差对比

![image-20241030171006324](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241030171006324.png)

![image-20241030171013541](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241030171013541.png)

![image-20241030171046332](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241030171046332.png)



问题：

1. 各个约束能否直接平移过来？是否需要修改？
2. 如何在mesh上卷积





1. 流程图基本和论文中的一样，只不过把PDE换成了优化？看一下能不能直接换，或者改一下流程，以更适合优化

   好像不能直接用，解PDE的话使用GCN拼成微分方程，所以可以用，但是优化的话，loss中的一些项不能完全用GCN拼，还需要信号值$\phi$，只用嵌入向量是不行的。？

2. 用CNN+RNN的方式，但是CNN换为GNN，每个时间步的输出也可以用GCN，有限差分，AD+差分。



现在不需要管模型的效率，即解压缩的次数，可以之后再考虑。现在先把确定下来一个可行的流程。

1. 如何在mesh上对顶点的特征（lsf,face,角度等）进行卷积。
2. 如何求梯度。



画出流程图

1. GNN+RNN 论文3的流程
2. GNN+RNN 使用GCN
3. GNN，一次前向。不使用RNN，只用一次前向过程，完成水平集的演化。

**看解PDE的论文，主要看流程。**

Deep Learning-based surrogate models for  parametrized PDEs: handling geometric variability  through graph neural networks（GNN解PDE，含障碍）

1. 时序相关，RNN？
2. 稳态PDE

**mesh卷积：**

1. meshcnn （用edge 做卷积）

2. Laplacian2Mesh: Laplacian-Based Mesh Understanding （用映射后的顶点做卷积）

3. MeshNet: Mesh Neural Network for 3D Shape Representation （用face做卷积）

**求梯度的方法：**

1. GCN论文

   ISOMETRIC TRANSFORMATION INVARIANT AND  EQUIVARIANT GRAPH CONVOLUTIONAL NETWORKS

2. 有限差分

   参考：PhyCRNet Physics-informed convolutional-recurrent

3. 有限差分+AD

   CAN-PINN: A Fast Physics-Informed Neural Network Based on Coupled-Automatic-Numerical Differentiation Method

看拓扑论文





#### mesh卷积：

###### meshcnn （用edge 做卷积）

类似于cnn，但是是在不规则的三角网格上进行。在edge上设计的对称卷积和池化操作。

网格为流形网格，可能有边界。

![image-20241031153458806](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241031153458806.png)

edge feature 是5维向量：两个face的二面角、两个内角、edge 长度之比。如下所示：

**网格卷积：**

![image-20241031154548092](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241031154548092.png)

![image-20241031153717549](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241031153717549.png)

根据选择的遍历边的起点不同，遍历的次序也不同，但只有两种不同的遍历次序，即(a,b,c,d)或(c,d,a,b)，通过以下方式确保输入的卷积不变性：

![image-20241031154940934](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241031154940934.png)

对于全局特征聚合的任务，通过放置一个全局池化层，确保初始edge 的排序不会影响卷积的结果。

**池化操作：**

如何决定哪些边要折叠呢？每个网格池化层都实例化一个要保持的目标边数(在代码中使用——pool_res参数)。网格池化层只是根据边缘特征的平方大小对边缘进行排序。然后迭代折叠网格边缘，直到达到目标边缘数。

mesh池化过程：（5个edge转换维2个）

![image-20241031154035417](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241031154035417.png)

池化时是将5个edge合并为2个，同一个面的edge feature合并为一个edge feature.新合并的边特征为之前三个边特征的平均值。

![image-20241031161850387](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241031161850387.png)

**反池化操作：**

该模块没有可学习的操作，主要通过池化操作时保存的连接关系来恢复上采样的拓扑。



这种卷积在mesh的分割和分类上效果很好。其中分割不需要考虑全局的特征，因此不需要全局平均池化层。分类需要考虑全局特征，有全局平均池化层。 并且具有对旋转、平移和缩放不变性；



###### Laplacian2Mesh: Laplacian-Based Mesh Understanding （用映射后的顶点做卷积）

###### MeshNet: Mesh Neural Network for 3D Shape Representation （用face做卷积）

