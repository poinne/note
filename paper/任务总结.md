##### 任务：

训练一个模型，输入一个三维离散网格，以及一些控制点（插值点和障碍点），输出一条满足控制点约束和光滑性约束的曲线。

思想：利用深度学习+水平集来实现。

通过深度学习来解定义在网格上的水平集函数，得到最终的零水平集，并采样输出。

---

**水平集方法：**

水平集方法通过比目标维度高一维的水平集函数（LSF）的零水平集隐式地表示曲线，能够自然地处理目标的复杂拓扑变化。

一般来说，水平集方法需要在目标周围初始化水平集函数，再基于精心涉及的能量函数，通过求解偏微分方程迭代更新水平集函数实现曲线演变，达到最小化能量函数的目标，此时LSF的零水平集即为目标边界。

水平集函数的演变通常由一阶PDE描述：
$$
\frac{\partial \phi}{\partial t} + F(\nabla\phi) = 0
$$
其中，$\phi$是水平集函数，$F$是水平集的几何性质相关的函数，在这个任务中，表示水平集各点的速度。

当涉及到界面或边界的曲率时，可能会引入高阶导数。

我的理解：上述PDE表示 $\phi$ 随着时间 $t$ 的变化，梯度 $\nabla\phi$ 的变化情况。 $\nabla\phi$ 表示的是各个位置变化的方向，$F$ 则是表示各点变化的速度。

---

**深度学习求解PDE：**

目前，深度学习应用于偏微分方程的求解已经有了大量的文章，针对目前已经看过的文章，总结如下：

对于低维的PDE，learning方法通常没有优化方法快，但是由于简单性以及适用于解决大量偏微分方程问题的多功能性，learning方法在低维PDE中也有很多应用，最常用的方法是FINN。

FINN 将



---

**深度学习处理网格：**

深度学习处理网格可以分为两类：

基于图结构的方法和基于网格结构的方法。

**基于图结构的方法：**

又可以分为两类，基于图谱理论、使用图邻接对欧式空间卷积进行扩展。

这两种方式的区别主要是对于卷积的定义不同

- 基于图谱理论的卷积

  在图谱理论中，图的卷积基于图的**拉普拉斯矩阵**的特征向量（即傅里叶基）。

  首先通过傅里叶变换将信号和卷积核映射到频域，然后在频域中逐元素相乘，最后通过逆变换将结果映射回时域。

  这种方式的卷积需要求解全图的拉普拉斯矩阵并对其进行分解，在图规模很大时，代价很大，所以有很多工作对这种卷积进行了修改。

- 基于空间域的卷积

  基于空间域的卷积通常是欧几里得域中卷积的模仿。因为图节点的邻居节点数量不一致，有各种的方法进行处理。

**基于网格结构的方法：**

 基于图结构的方法只考虑了图结构，而对于 3D 空间中的网格，还有其他独特的属性可以使用。

研究人员提出了许多网格学习模型，它们可以根据处理策略分为两类。一种是在3D欧氏空间中定义卷积，完全忽略网格结构，称为外在卷积。另一种是根据mesh代表2-流形的点，模仿2D平面上的定义来定义卷积，通常称为内在卷积。

**外在卷积**

通过外部的视角和规则对网格模型进行卷积。

<img src="https://raw.githubusercontent.com/poinne/md-pic/main/image-20241010203140425.png" alt="image-20241010203140425" style="zoom:67%;" />

- 通过多个视角的2D图像对3D空间中的表面进行学习。

- 将网格对象转为体素进行卷积。

这类方法无法得到和利用网格内部的属性，只能对网格的外在进行处理。


**内在卷积**

因为mesh 的局部是2-manifold，与平面局部同胚，可以使用类似欧式空间中的卷积。

**GCNN（Geodesic Convolutional Neural Networks）**

- **定义**：GCNN 使用定义在测地盘（geodesic disk）上的函数来提取局部特征。
- 工作原理
  - 测地盘是以某个顶点为中心，按照测地距离选择邻域内的点。
  - 在这个测地盘上，GCNN 定义卷积操作，以捕捉该区域内的特征。
  - 这种方法强调了点之间的测地距离，使得卷积操作能够更好地反映流形的几何特性。

**ACNN（Algebraic Convolutional Neural Networks）**

- **定义**：ACNN 利用热核（heat kernel）来提取特征。
- 工作原理
  - 热核是描述在流形上热传导过程的一种数学工具，它能有效地捕捉局部和全局特征。
  - ACNN 通过使用热核作为卷积核，计算流形上点的特征，重点关注点之间的关系和相互影响。
  - 这种方法有助于捕捉流形的平滑性和连续性，适用于处理具有复杂结构的场景。

**DCNN（Diffusion Convolutional Neural Networks）**

- **定义**：DCNN 基于概率转移矩阵进行特征提取。
- 工作原理
  - 概率转移矩阵描述了在图上信息如何通过边传播。这可以视为信息在图中的扩散过程。
  - DCNN 利用这一扩散过程来定义卷积操作，将来自邻居的信息聚合到中心点。
  - 这种方法可以捕捉到网络中信息传播的动态过程，适用于处理具有复杂连接关系的图结构。

___

**深度学习在网格上求解PDE**

如何

---

**深度学习求解水平集**



---

##### 整理1

1. 如何表示mesh上的lsf？

- dl中如何处理mesh的输入
  - 基于图结构的方法，输入为顶点之间的邻接关系，通过邻接矩阵的方式作为输入。
    - 在模型内部，图的表示可以包含邻接矩阵和特征矩阵，经过图卷积操作后得到新的顶点特征。
    - 每个节点（顶点）在模型中拥有一个特征向量，经过多个卷积层和非线性激活后，节点特征会被逐步更新，反映与邻居的关系。
    - 在某些情况下，可以通过全局池化层（如最大池化或平均池化）来获得整个图的全局特征表示，用于后续的分类或回归任务。
    - **卷积的方法也是使用图卷积的方法来做。**
  - 基于网格结构的方法，输入为顶点坐标(N * 3)，面信息（M * K）[K边形]，特征信息（附加的顶点或面信息）。
    - 输入数据在模型中通常以顶点坐标和面索引的形式进行处理。每个顶点都有对应的特征向量，模型通过卷积操作在三角面上提取特征。
    - 网络可能会对每个顶点的邻域（局部补丁）进行特征提取，通过对邻域内的顶点特征进行聚合来更新每个顶点的特征。
    - **卷积的方法会利用网格的内在属性。**
  - **这两种方式的区别主要是对于卷积的定义不同。**
- 如何将lsf加入mesh输入中
  - 各顶点的特征向量多一维，存lsf值
  - 将特征向量通过FC层降维，得到lsm \\ 体素
  - 根据输入构建水平集图（二维）
  - nerf的方式，将一个场景模型的表面存储在神经网络中。缺点是一个模型只能保存一个曲面

2. 如何训练：

- 用sdf？用sdf loss做监督
- 在输入的对象（图像\模型）上定义sdf，并设计sdf loss来进行模型训练。训练过程和一般的模型训练过程相同。
- 用lsf？解pde，类似PINN
  - 在输入的对象（图像\模型）上定义lsf，将要求解的水平集函数和一些约束条件作为loss，并使用自动微分和手动推导的水平集梯度进行梯度计算，从而更新水平集。

---

##### 整理2

1. 如何隐式表示曲线曲面？
   - 在输入的图像或模型上定义水平集，更新水平集，最终使水平集函数$\phi(x) = 0$的点即为曲线或曲面。
   
   - 用大量数据来训练一个过拟合的模型，来隐式表示曲线或曲面(NeuroGF,Nerf)。
   
     

---

1. 使用GNN处理mesh输出，并提取特征，结合RNN（LSTM）进行水平集的更新，但是PhyCRNet 模型使用CNN+LSTM，相比于传统方法，并没有什么亮点，不过比PINN方法的外推性和泛化性好一点。如果使用GNN+LSTM的话，也要找到优势才行，比如速度快，精度高（不太现实），泛化性能强等等。																				







##### 思路：

先对任务进行拆分：

**问题1：如何处理输入的网格对象？**

**mesh的表示方式：**

1. 网格由$(V,F)$ 对定义，其中$V = {v_1,v_2,...,v_n}$是$R^3$中的顶点坐标集合。$F$定义连通性，是三角形网格的顶点三元组。边$E$可以由给定的$(V,F)$对表示。且$V,E,F$都可以与各种特征关联。（这个是可以在模型中处理的）

   控制点可以通过输入顶点坐标，切法向输入归一化的向量。

   （meshcnn)

2. 用GNN的表示方法：

   <img src="../../../AppData/Roaming/Typora/typora-user-images/image-20241029103549565.png" alt="image-20241029103549565" style="zoom:67%;" />

   邻接列表的第i个元素代表第i条边，元素中的内容代表边的两个顶点。

   顶点列表和边列表中的元素代表各个顶点和边上定义的标量（也可以是向量）

   这种表示方式没有考虑到面的信息。

**问题2：如何处理约束信息？**

约束信息有水平集约束、初边值约束、插值约束、障碍约束、切法向约束、光滑性约束。

1. 将约束放入损失函数中。

   优点：简单，

   缺点：训练的模型泛化能力差

2. 将约束信息编码为与顶点相同维度，用于损失函数的计算。

   优点：灵活，泛化能力好

   缺点：有些约束可能不好处理，暂时不清楚怎么做

3. 将约束硬编码在模型中。

   优点：强制生成的曲线满足。

   缺点：上述约束很多可能都不能硬编码在模型中。

**问题3：如何在模型中表示水平集？**

1. 在模型的最后一层的输出作为水平集函数的值，通过带有水平集的损失函数进行学习。
2. 用每个节点的特征向量的一维表示水平集函数的值，（显式）
3. 用编码后的特征向量表示水平集函数的值（隐式）

**问题4：如何结合约束对水平集进行更新？**

1. 将时间看作额外的一维，将约束条件和水平集函数作为损失，进行训练（PINN）。

   优点是：简单，容易实现。基本上是无监督训练，不需要太多训练数据。

   缺点是：泛化能力很差，训练好后无法处理不同的约束。

2. 同时使用物理约束和数据约束作为损失，使用大量的数据进行有监督训练。

   对应问题2的第一种方式，这种方法时间也是额外的一维，训练过程和一般的有监督训练相同。

3. 对输入的数据进行卷积编码后，通过RNN对嵌入向量进行卷积处理，每次循环对应一个时间步。通过物理约束作为损失。

   借助有限差分和自动微分进行处理。

   优点：该方法通过RNN来处理时间这一维度，而不是作为额外的一维进行处理。借助当前RNN(如LSTM)，可以更好地处理水平集的演化。

   将初始值作为输入，边界硬编码，损失只有物理函数，无监督训练。

   缺点：速度方面不能保证比传统方法快（看得论文是处理二维情况，用有限差分卷积求梯度）

4. 将输入数据进行编码，用GCN来近似水平集函数中的微分算子，整个训练过程类似于传统的数值求解PDE方法，但是每次迭代的时间步更大。

   这种方法将物理信息值嵌入模型中，而不是固定在损失中。model solver可以使用RNN或GNN。

   对于用近似的微分算子构成的水平集函数，对时间的离散可以使用隐式欧拉法。使用梯度下降法求解。

   这种方法的的求解速度要比传统数值方法快。

   

###### 思路1：

类似于PINN，将水平集函数的残差以及其它约束都固定在损失函数中，使用GNN对输入的网格进行卷积处理，在模型的最后一层输出水平集函数的值，通过自动微分和损失函数来训练模型。

（不可行）



###### 思路2：

根据控制点坐标初始化模型上的水平集值。（用什么方法初始化？）

将mesh模型和约束（插值和障碍点坐标、切法线约束）输入GNN中。（mesh模型以什么形式输入，输入后用什么形式保存，切法线约束用什么形式输入）

通过MLP将水平集（标量）编码为嵌入向量，输入模型求解器，用GCN来近似离散流形上的各种微分算子。（之前论文中GCN是在欧式空间进行卷积的， 如何修改为在流形空间进行卷积，并且之前的GCN的一些变换不变和等变性是否需要？）

输入的约束也会被编码为嵌入向量，用于求解器使用。（切法线约束如何编码，如何使用）

求解器将各个近似微分算子和相应的系数组合起来，构成lsm演化的PDE，PDE中额外包括输入的约束，以及sdf约束、光滑性约束。

使用隐式欧拉来求解水平集函数，每一步通过BB法来迭代求解下一个时间步的值。



基于曲线演化方法，

**数据集构造**



**输入数据格式：**

mesh数据：$(V,F)$

控制点：$V_{interp}、V_{obs}$

切法向：$list:(a_1,a_2...), a_i = \{v_i,n_i\}$

**根据控制点坐标初始化模型上的水平集值：**

在输入模型前，先对模型进行预处理，根据插值点生成初始水平集。

根据插值点，沿模型的edge生成一个圆环，然后使用fast marching 构造初始水平集。

**mesh在模型中的表示方式：**

网格由$(V,F)$ 对定义，其中$V = {v_1,v_2,...,v_n}$是$R^3$中的顶点坐标集合。$F$定义连通性，是三角形网格的顶点三元组。边$E$可以由给定的$(V,F)$对表示。且$V,E,F$都可以与各种特征关联。（主要处理的是顶点的特征，即标量值水平集）

控制点可以通过输入顶点坐标，切法向输入指定点归一化的向量（6维）。

（meshcnn)

**通过MLP将水平集（标量）和约束编码为嵌入向量，输入模型求解器，用GCN来近似离散流形上的各种微分算子。**

$IsoGCN$是对欧式空间中进行的卷积，不能直接在2流形上使用，需要修改$IsoGCN$的卷积操作，使其可以处理网格，参考MeshCNN及其相关文章。

输入的控制点和切法向也通过mlp进行编码，用于之后水平集函数的使用。

**求解器将各个近似微分算子和相应的系数组合起来，构成lsm演化的PDE，PDE中额外包括输入的约束，以及sdf约束、光滑性约束。**

水平集函数为：
$$
\frac{\partial \phi}{\partial t}  = - F(\nabla\phi) + \lambda_1E_{shape} +\lambda_2E_{topology}
$$
约束可以分为内部约束和外部约束，区别在于是否使用一二阶导。

内部约束：

eikonal约束：$E_{eikonal} = \int_M\frac{1}{2}(|\nabla\phi_i|^2 - 1)^2$

光滑性约束：$E_{smooth} = |\nabla\phi_i|div(\frac{\nabla\phi_i}{|\nabla\phi_i|})$

外部约束：

插值点约束：$L_{interp} = \sum^{M}_{p}(\phi_i(x_p) - 0)$，M为插值点数量，$x_p$是插值点

障碍点约束：$L_{obs} = - \sum^{N}_{p}(\phi_i(x_p))$ [?]，N为插值点数量，$x_p$是障碍点

切线约束：$L_{tan} = \sum^{M}_{p}<\nabla\phi(x_p),\tau_p>$,M为插值点数量，$x_p$是插值点，$\tau_p$是插值点对应的输入切向量。

eikonal约束：是否需要eikonal约束，需要的话怎么加？

光滑性约束：可以直接加载水平集演化方程中。

插值点约束：

障碍点约束：

切线约束：

**使用隐式欧拉来求解水平集函数，每一步通过BB法来迭代求解下一个时间步的值。**









使用GNN+可以近似微分算子的GCN模块，使用多个GCN模块来近似水平集函数和各种约束，然后sovler进行求解。

GNN和MLP来处理输入的mesh和控制条件，编码为特征向量和控制向量。

之后使用GCN模块来近似各个需要的微分算子，将特征向量和控制向量输入近似微分算子进行卷积计算，

最后通过优化方法（如梯度下降等）对模型进行更新。

最终的特征信息通过解码器进行输出。

训练时同样是有监督训练，通过mse来训练GCN模块和编码器。

这个思路和传统的数值解法类似，不过PDE中微分算子的计算通过图卷积完成，同时迭代过程在潜在空间中进行。

**思路2.1：**

基于最小化能量方法(变分方法),这种方法可以方便的添加各种约束。

**数据集构造**



**输入数据格式：**

mesh数据：$(V,F)$

控制点：$V_{interp}、V_{obs}$

切法向：$list:(a_1,a_2...), a_i = \{v_i,n_i\}$

**根据控制点坐标初始化模型上的水平集值：**

在输入模型前，先对模型进行预处理，根据插值点生成初始水平集。

根据插值点，沿模型的edge生成一个圆环，然后使用fast marching 构造初始水平集。

**mesh在模型中的表示方式：**

网格由$(V,F)$ 对定义，其中$V = {v_1,v_2,...,v_n}$是$R^3$中的顶点坐标集合。$F$定义连通性，是三角形网格的顶点三元组。边$E$可以由给定的$(V,F)$对表示。且$V,E,F$都可以与各种特征关联。（主要处理的是顶点的特征，即标量值水平集）

控制点可以通过输入顶点坐标，切法向输入指定点归一化的向量（6维）。

**通过MLP将水平集（标量）和约束编码为嵌入向量，输入模型求解器，用GCN来近似离散流形上的各种微分算子。**

$IsoGCN$是对欧式空间中进行的卷积，不能直接在2流形上使用，需要修改$IsoGCN$的卷积操作，使其可以处理网格，参考MeshCNN及其相关文章。

输入的控制点和切法向也通过mlp进行编码，用于之后水平集函数的使用。

**将水平集演化看作优化问题，将各种约束作为损失函数**

损失函数为：$\mathcal{E} = E_{shape} + E_{sdf}$
$$
E_{shape} = w_{interp}E_{interp}(\phi) + w_{obs}E_{obs}(\phi) + w_{smooth}E_{smooth}(\phi) + w_{tan}E_{tan}(\phi)\\
E_{sdf}(\phi) = \int_M \frac{1}{2}(|\nabla\phi|^2 - 1)^2dM
$$
用GCN的组合来求损失函数，使用梯度下降训练网络参数。 



**思路2.2：**

基于最小化能量方法(变分方法),这种方法可以方便的添加各种约束。

**数据集构造**



**输入数据格式：**

mesh数据：$(V,F)$

控制点：$V_{interp}、V_{obs}$

切法向：$list:(a_1,a_2...), a_i = \{v_i,n_i\}$

**根据控制点坐标初始化模型上的水平集值：**

在输入模型前，先对模型进行预处理，根据插值点生成初始水平集。

根据插值点，沿模型的edge生成一个圆环，然后使用fast marching 构造初始水平集。

**mesh在模型中的表示方式：**

网格由$(V,F)$ 对定义，其中$V = {v_1,v_2,...,v_n}$是$R^3$中的顶点坐标集合。$F$定义连通性，是三角形网格的顶点三元组。边$E$可以由给定的$(V,F)$对表示。且$V,E,F$都可以与各种特征关联。（主要处理的是顶点的特征，即标量值水平集）

控制点可以通过输入顶点坐标，切法向输入指定点归一化的向量（6维）。

借助输入的(V,F)进行流形上的有限差分卷积，得到输入mesh的差分图（包括梯度和拉普拉斯和信号值），

通过RNN来更新差分图，并结合事先生成的真实值进行监督学习。

**将水平集演化看作优化问题，将各种约束作为损失函数**

损失函数为：$\mathcal{E} = E_{shape} + E_{sdf}$
$$
E_{shape} = w_{interp}E_{interp}(\phi) + w_{obs}E_{obs}(\phi) + w_{smooth}E_{smooth}(\phi) + w_{tan}E_{tan}(\phi)\\
E_{sdf}(\phi) = \int_M \frac{1}{2}(|\nabla\phi|^2 - 1)^2dM
$$
用GCN的组合来求损失函数，使用梯度下降训练网络参数。 





这个任务有几个步骤，每个步骤可以有哪些方法，这些方法的优缺点，性能对比如何。



###### 思路3：

使用GNN，在模型的最后一层输出水平集函数的值（或者用一个维度来表示水平集函数值，但这样是不是就不能卷积了？），通过自动微分和有限差分对Approximated Heaviside Function(AHF)以及各项约束进行计算。对模型进行有监督训练。

这个思路就是一般模型的训练思路，只不过模型训练过程中信号值是水平集函数，同时约束也和水平集函数有关（AHF 以及导数）