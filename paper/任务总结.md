训练一个模型，输入一个三维离散网格，以及一些控制点（插值点和障碍点），输出一条满足控制点约束和光滑性约束的曲线。

思想：利用深度学习+水平集来实现。

通过深度学习来解定义在网格上的水平集函数，得到最终的零水平集，并采样输出。

---

**水平集方法：**

水平集方法通过比目标维度高一维的水平集函数（LSF）的零水平集隐式地表示曲线，能够自然地处理目标的复杂拓扑变化。

一般来说，水平集方法需要在目标周围初始化水平集函数，再基于精心涉及的能量函数，通过求解偏微分方程迭代更新水平集函数实现曲线演变，达到最小化能量函数的目标，此时LSF的零水平集即为目标边界。

水平集函数的演变通常由一阶PDE描述：
$$
\frac{\partial \phi}{\partial t} + F(\nabla\phi) = 0
$$
其中，$\phi$是水平集函数，$F$是水平集的几何性质相关的函数，在这个任务中，表示水平集各点的速度。

当涉及到界面或边界的曲率时，可能会引入高阶导数。

我的理解：上述PDE表示 $\phi$ 随着时间 $t$ 的变化，梯度 $\nabla\phi$ 的变化情况。 $\nabla\phi$ 表示的是各个位置变化的方向，$F$ 则是表示各点变化的速度。

---

**深度学习求解PDE：**

目前，深度学习应用于偏微分方程的求解已经有了大量的文章，针对目前已经看过的文章，总结如下：

对于低维的PDE，learning方法通常没有优化方法快，但是由于简单性以及适用于解决大量偏微分方程问题的多功能性，learning方法在低维PDE中也有很多应用，最常用的方法是FINN。

**FINNs**

[[博客](https://zhuanlan.zhihu.com/p/411843646)]

FINNs全称为 （Physics-informed neural networks），与传统的数据驱动的神经网络不同，PINNs 在学习过程中利用物理法则对模型进行指导，从而提高模型泛化能力，特别是在数据较少或噪声较大的情况下。

PINNs 通过训练神经网络来最小化一个损失函数，从而生成 PDE 的近似解。

PINN可以通过少量的数据进行PDE的求解，具体地，可以只通过初值和边界值以及PDE方程进行学习和求解。

为了实现只有初边值条件和方程即可约束神经网络，需要在损失函数上花心思，毕竟损失函数决定了神经网络训练的方向。PINNs的损失函数分为两块，一块是初始条件和边界条件，一块是方程。

- 表示空间-时间域边界上初始条件和边界条件偏差的项，

  使用初值和边界条件做约束条件比较简单，直接做一个MSE即可。

- 表示域内选定点上 PDE 残差的项。

  这部分是PINN的关键，即偏微分方程的残差，当输出的u和对应的导数满足方程时，f是等于0的。因此目标是让f尽可能的接近0。这样就实现了即使不知道真值u，也能计算出方程的Loss用于指导神经网络参数的更新，实现了非监督学习的效果。

通过最小化这些偏差，神经网络能够逼近 PDE 的解。

PINNs 的优势在于其灵活性，因为它们可以应用于各种具有挑战性的偏微分方程，而经典数值近似通常需要根据特定偏微分方程的具体情况进行定制。

损失函数中PDE残差的项需要对t进行求导，以及计算一些偏微分算子，这些都可以通过pytorch库提供的自动微分得到。

举例如下：

对于偏微分方程：

![image-20241012150835037](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241012150835037.png)

可以构造对应的损失函数：

![image-20241012150858220](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241012150858220.png)

因为PDE本身就是0，因此只需要最小化PDE的值的平方即可，而初始和边界条件则需要最小化其与gt值之差的平方。

**PINN训练过程**

PINN 训练时，输入的数据主要分为两类：

1. **边界条件和初始条件的数据**：
   - PINN的一个关键特点是，它可以处理具有**小数据**的PDE问题。因此，网络的训练数据通常是偏微分方程的**边界条件**和**初始条件**.
   - 这部分的数据属于有监督训练，即对于每个预测的值，都会提供对应的真值用于loss计算。
   - 这部分的数据，训练时初边值的loss和PDE残差的loss都会计算。

2. **内部点的采样数据**：
   - 为了使神经网络逼近PDE的解，PINN在**空间-时间域的内部**随机选择一些点。在这些点上，网络通过自动微分来计算PDE的残差（例如偏导数），并将PDE的残差引入到损失函数中进行优化。
   - 这些内部点并不需要提供确切的解值，而是通过自动微分评估解是否符合PDE的要求。因此，PINN能够在缺乏大量训练数据的情况下通过物理约束来指导网络的训练。
   - 这部分的数据属于无监督训练，即对于每个预测的值，没有对应的真值用于loss计算。
   - 这部分的数据，训练时只会计算PDE残差的loss。

PINN的输入特征：

- **时空坐标点**：即 \( (t, x) \) 的值，这些点可以是时间和空间域内的任意位置。
- **边界条件和初始条件**：这些条件会提供在特定时刻和特定空间边界处的已知解，作为训练的监督数据。

PINN 的训练过程主要是通过将输入的时空坐标和边界/初始条件结合在一起，并通过最小化损失函数（包含PDE残差、边界条件、初始条件的偏差）来优化神经网络的参数。

---

**深度学习处理网格：**

深度学习处理网格可以分为两类：

基于图结构的方法和基于网格结构的方法。

**基于图结构的方法：**

又可以分为两类，基于图谱理论、使用图邻接对欧式空间卷积进行扩展。

这两种方式的区别主要是对于卷积的定义不同

- 基于图谱理论的卷积

  在图谱理论中，图的卷积基于图的**拉普拉斯矩阵**的特征向量（即傅里叶基）。

  首先通过傅里叶变换将信号和卷积核映射到频域，然后在频域中逐元素相乘，最后通过逆变换将结果映射回时域。

  这种方式的卷积需要求解全图的拉普拉斯矩阵并对其进行分解，在图规模很大时，代价很大，所以有很多工作对这种卷积进行了修改。

- 基于空间域的卷积

  基于空间域的卷积通常是欧几里得域中卷积的模仿。因为图节点的邻居节点数量不一致，有各种的方法进行处理。

**基于网格结构的方法：**

 基于图结构的方法只考虑了图结构，而对于 3D 空间中的网格，还有其他独特的属性可以使用。

研究人员提出了许多网格学习模型，它们可以根据处理策略分为两类。一种是在3D欧氏空间中定义卷积，完全忽略网格结构，称为外在卷积。另一种是根据mesh代表2-流形的点，模仿2D平面上的定义来定义卷积，通常称为内在卷积。

**外在卷积**

通过外部的视角和规则对网格模型进行卷积。

<img src="https://raw.githubusercontent.com/poinne/md-pic/main/image-20241010203140425.png" alt="image-20241010203140425" style="zoom:67%;" />

- 通过多个视角的2D图像对3D空间中的表面进行学习。

- 将网格转为体素进行卷积。




**内在卷积**

看不明白。。

___

**深度学习在网格上求解PDE**



---

**深度学习求解水平集**