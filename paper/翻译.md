### 1. 引言

3D网格可以被视为最流行的离散虚拟表面和体积表示形式之一。由于其简单性，3D网格在今天广泛应用于各种领域，几乎所有个人电脑、平板电脑和智能手机中都集成了图形处理单元（GPU），这些电子设备部分专用于从3D网格渲染图像。

在所有使用网格的应用领域（如计算仿真、娱乐、医学成像、数字遗产、计算机辅助设计、电子商务等），对精度的需求从未停止增加。这导致了包含大量元素的网格的生成，这些网格的处理、可视化和存储变得复杂。3D网格压缩是一种潜在的解决工具。首先，它减少了数据大小，这对于存储和传输网格非常有用。此外，一些算法还在压缩数据中嵌入了输入模型的多个版本。这使得大网格在低能力终端上可以逐步传输和交互式可视化。

2005年，两篇非常完整的综述文章总结了网格压缩的开创性工作[Alliez and Gotsman 2005; Peng et al. 2005]。然而，从那时起，新的方法出现了，为3D网格压缩算法带来了新的特性（大网格压缩、网格序列压缩、随机访问等）。本文的目的是总结最初的方法，并关注自2005年以来发展的相关贡献。

网格可以是静态的也可以是动态的。在介绍了初步知识后，本文的第一部分将致力于静态网格压缩方法，并将其分为三类。

- **单速率算法**：构建输入网格的紧凑表示。解压缩算法生成的网格与输入模型相同或仅略有不同。
- **渐进算法**：在解压过程中，随着更多数据被解码，逐步重建不同的细节层次。用户无需等待所有数据下载和解压即可可视化模型，这在远程可视化环境中非常有用。这些算法还用于根据设备渲染能力、网络约束或视点选择最佳的细节层次进行显示。
- **随机访问算法**：用于仅解压请求的输入网格部分，以节省资源。它们提供对不适合设备主存储器的模型的访问，但用户无法概览未选择的部分。渐进随机访问方法用于以不同的细节层次解压输入模型的不同部分。

渐进和随机访问算法也可以用于单速率压缩，尽管它们通常不如纯单速率方法有效。

本文的最后一部分致力于动态网格压缩。动态网格是一种新兴的媒体内容，可能携带大量数据（大网格×大帧数）。类似于2D视频，动态网格压缩需要特定的特性，如可扩展性和流媒体能力。

图1提供了现有技术的分类；对于前面描述的每个部分，一个综合表总结并比较了最相关的方法。

### 2. 网格和压缩的基础知识

网格可以定义为不同元素的层次结构，如图2所示。顶点是网格的基本元素，它们在通用的三维笛卡尔空间中定义一个位置。边是连接网格两个顶点的线段。面是由闭合边路径定义的多边形。在本次综述中，我们假设每个面都是简单连接的：即它没有孔洞，且其边界没有与该面相交的两个以上的边的顶点。称为3-cells的三维单元是由其边界定义的多面体，这些边界由选定的面形成的闭合表面组成。网格中包含的信息通常分为三类：

— 几何信息是网格中每个顶点在三维笛卡尔空间中的位置。

— 拓扑信息（有时称为拓扑结构或结构）描述了网格元素之间的相互关系。

— 可选的属性信息将标量或离散属性与网格元素关联，这对于应用程序非常有用（如颜色、法线、纹理坐标等）。

#### 网格压缩的范围
本综述仅涉及几何和拓扑信息的压缩。两种信息类型的大多数压缩率将以每顶点的比特数（bpv）表示。

#### 表面网格和体积网格
表面网格定义了可以闭合或不闭合的表面，它们不需要是三维单元的边界。如果某些边仅与一个面相邻，则表面网格被认为包含边界。体积网格定义了由一组三维单元填充的体积。

#### 网格序列
网格序列是按时间顺序排列的一系列网格。需要时间上的一致性，并且需要相对于对象或场景的演变以足够快的速率进行时间采样。我们可以区分两种不同类型的序列：
- **时间一致的网格序列**：这些序列中的顶点数、连接性和拓扑结构是恒定的，通常称为动态网格或动画网格。
- **时间不一致的网格序列**：这些序列中的顶点数和连接性随时间变化，拓扑结构可以是变化的或恒定的。

在第一种情况下，序列由初始网格顶点随时间的几何演变组成。在第二种情况下，在时间点t和时间点t+1之间的顶点不一定存在自然联系。

#### 顶点的度数
与一个顶点相邻的边的数量称为该顶点的度数（或价）。同样，面的边数或三维单元的面数也称为该面的或该三维单元的度数（或价）。常见的表面网格情况是度数为三（三角面）和度数为四（四边形面）。如果面的度数大于三，则该面不一定是平面的，但如果某些顶点离中位面较远，渲染可能会变得棘手。同样，体积网格的常见情况是度数为四（四面体）或六（六面体）的三维单元。

#### 网格的规则性
一些网格的连接性被称为规则的，因为它们由相同模式的重复组成。如果只有少数网格元素的连接性不规则，则该网格称为半规则网格。当网格的连接性不包含规则结构时，它被称为不规则网格。

#### 2-流形网格
如果表面网格的所有顶点都有同胚于闭扇或开扇的邻域，则该表面网格为2-流形，如图4所示。

### 

#### 边界和非边界网格
一个网格，如果包含边界，则其顶点邻域是同胚于开扇的。这个综述将讨论流形网格和非流形网格的压缩。

#### 面的方向和网格的可定向性
面的方向是其顶点的循环顺序。在一个网格中，如果两个相邻面的方向相反，则它们的方向是兼容的。一个网格如果所有面的方向都兼容，则称为可定向的。

#### 欧拉特征和拓扑类型
一个二维流形可定向网格的欧拉特征χ定义了它的拓扑类型。它等于χ = v - e + f，其中v、e和f分别是网格的顶点数、边数和面数。一个网格如果可以沿着2g个闭合环切割而不使其断开，则称其具有g属。直观地说，属是网格的柄的数量。可以证明，欧拉特征也等于χ = 2(s - g) - b，其中s是网格的连通分量数，b是其边界环的数量。这使得我们能够证明，一个低属且具有大量面的二维流形可定向三角网格，其面的数量大约是顶点数量的两倍，并且其顶点的平均度数为六。

#### 网格文件格式和索引数据结构
许多网格文件格式（OFF、PLY、OBJ、VRML、X3D等）基于索引数据结构。该结构的第一部分由所有顶点坐标的列表组成，同时引入了网格顶点的顺序。第二部分描述了网格的连接性。每个条目按循环顺序列出一个面的所有顶点。对于体积网格，每个三维单元的面也可以以相同的方式存储。这种数据结构的优点是简单。此外，它可以存储任何类型的网格。大多数网格压缩算法以这种结构作为输入。

---

### 3. 单一速率网格压缩的现状

压缩网格与压缩其他类型的多媒体数据（如声音、图像或视频）不同。声音、图像和视频的结构在编码器和解码器中是预先已知的。然而，网格的结构不一定是规则的。其连接性在压缩前对于编码器来说是完全未知的。因此，除了必须编码几何信息（顶点位置），如同为图像编码像素颜色那样，网格编码器还必须编码连接性。

#### 3.1 连接性压缩

所有连接性压缩技术的基本原则是对网格元素进行遍历，并根据遇到的配置发出符号。关键在于这种遍历定义了网格元素的新编号，不同于输入的索引数据结构中使用的编号。生成的符号随后使用熵编码，例如霍夫曼编码【Huffman 1952】或算术编码【Rissanen and Langdon 1979】。本节提供的压缩率仅涉及连接性。

##### 3.1.1 三角带编码

渲染一个重要的三维网格需要高计算能力。GPU设计用于快速并行执行网格渲染操作。有效的将网格数据从计算机中央内存传输到GPU内存的解决方案至关重要，因为内存传输是一个耗费大量CPU周期的昂贵操作。好的网格数据传输方法可以显著减少渲染时间。三角带和三角扇是用于此目的的网格表示法。三角扇是定义共享一个公共中心顶点的一组三角形的顶点序列。三角带是顶点序列，其中每个添加的顶点与前两个顶点定义一个新三角形。这些方法比索引表示更有效，因为后者需要三个顶点索引来编码每个三角形。实际上，在编码第一个三角形后，一个新顶点索引编码了新三角形的连接性。

在三角带中，顶点总是按照相同的顺序来形成新三角形。广义三角带不总是遵守此顺序以生成更长的带。然而，为了保持三角带结构，在标准顺序未被遵守时会添加一个虚拟三角形。为了编码一个虚拟三角形，必须重复一个顶点引用。如果广义三角带足够长，三角形与顶点的数量比接近1。

Deering【1995】的广义三角网格格式是网格压缩的最早工作之一，其中包括广义三角带。Deering注意到，在广义三角带中，许多内部顶点被编码了两次。因此，他建议将它们推入一个16位队列，并在需要时通过队列位置引用它们。这个队列减少了重用顶点编码的成本。然而，所有网格顶点平均仍被编码两次，这不是很有效。实验结果显示，Deering的算法实现了从3.3到9.8 bpv的连接性压缩率。

广义三角网格必须最大化队列中重用的顶点数量。大多数网格带化技术获得的带大小和带顺序并不适合这个目标。因此，Chow【1997】设计了生成高效广义三角网格的算法。这些算法根据前一带中可重用的顶点数量选择新的广义三角带进行编码。

Bajaj等人【1999b】提出了一种替代的分层表示法。顶点层是非交叉的顶点字符串。在大多数情况下，它们通过一条边距离分开，并在网格上形成同心圆。顶点层之间的三角形层包含三角带和三角扇。这种方法可以以大约1.5到6 bpv的速率压缩网格连接性，并能处理非流形网格。

##### 3.1.2 平面图的生成树编码

网格的连接性可以建模为一个图。对于表面网格，顶点是图的节点，通过边连接以形成面。这种网格和图之间的类比解释了为何一些著名的图论结果可以应用于网格连接性的压缩。Tutte【1962】【1963】首先提出了一个公式来枚举平面三角化和平面地图。第一个枚举允许计算后来称为Tutte熵的东西。这个熵大约等于3.25 bpv，代表了任意表面三角网格连接性的熵的上限。这个值被用来证明几种三角网格连接性编码方案的最优性【Alliez和Desbrun 2001b】。Turan【1984】是第一个提出一种实际方法，通过顶点生成树编码一个平面无标签图，编码速率约为12 bpv。

##### 3.1.3 网格的生成树编码

平面图编码技术对一些三维网格编码技术产生了影响。例如，Taubin和Rossignac【1998】的拓扑手术算法通过两个生成树（一个顶点生成树和一个三角形生成树）以大约2.5到6 bpv的速率编码三角网格。在三角形数量是顶点数量两倍的情况下，这个算法的变体可以保证6 bpv的连接性压缩（2 bpv用于顶点生成树，每个三角形2位用于三角形生成树指示每个节点有零、一个或两个子节点）。Diaz-Gutierrez等人【2005】的手套算法使用两种顶点生成树（手和手套树）编码一个属为0的网格。这些树被构建成一个遍历整个网格的三角带循环。树的编码成本为2 bpv，每个三角形额外一个位允许重建三角带。总的保证成本因此为4 bpv。这种表示还嵌入了一种无层次多分辨率结构（通过两种类型的可折叠边）和带化。实验结果报告连接性压缩率平均约为1.5 bpv。Li和Kuo【1998a】的算法通过其对偶图编码三角网格的连接性。对偶图的每个节点与三条边相交。因此，编码遍历只需执行网格对偶图的广度优先遍历，并输出每条边一个二进制符号，指示该边是否连接到一个已访问的节点。

##### 3.1.4 三角形遍历编码

一些算法使用区域增长的方法，通过生成由条带组成的三角形生成树来编码网格。为了生成这些树，算法使用广度优先遍历迭代处理网格三角形。在每一步压缩过程中，一些面已经被遍历，而另一些没有。这两种面之间可能存在一个或多个封闭的边界。此类方法的优点在于其简单性。生成树容易生成，并直接包含所有网格元素。

Cut-Border Machine【Gumhold and Straßer 1998】遵循这种策略。它通过迭代遍历相邻三角形来扩展由初始三角形形成的边界。七种不同的符号编码边界是否通过插入新顶点进行扩展，边界是否被分割或两个边界是否被连接。该方案可以以约4 bpv压缩流形三角网格连接性。然而，这一结果仅适用于相对规则的网格。当两个边界连接时，必须编码一个偏移量以指定相关的顶点。因此，该算法不能保证压缩率的紧密上限。

Rossignac【1999】的Edgebreaker算法具有固定格式（每个三角形一个符号，没有额外偏移），保证了4 bpv的成本。实际上，在熵编码之后，网格以约1.8到2.4 bpv的速率被编码。该算法通过迭代遍历其面的方式编码三角网格的连接性。每次遍历一个新面时，编码其补丁的五种配置之一。然后删除该面，处理相邻的面。

一些源自Edgebreaker的方案提出了保证最坏情况编码成本为3.67 bpv【King和Rossignac 1999】，然后是3.55 bpv【Gumhold 2000】。提出了具有线性时间和空间复杂度的解码算法【Isenburg和Snoeyink 2000b；Rossignac和Szymczak 1999】。Szymczak等人优化了最初的方案以编码高规则性的网格【Szymczak 2003；Szymczak等人 2003】。这种方法在大规则网格中具有1.62 bpv的最坏情况编码率。Coors和Rossignac【2004】使用Delphi编码器添加了一种基于网格几何的连接性预测方法。Edgebreaker当前顶点的配置通过其平行四边形预测位置与活动门顶点位置之间的距离来预测。作者声称平均连接性压缩率低于0.75 bpv。Gumhold【2005】提出优化一个马尔可夫模型，其中每个Edgebreaker符号都是一个状态，以设计一个渐进最优的算术编码器。Ying等人【2010】设计了一个算法，通过选择下一个边缘门来最小化“S”符号的数量。他们还构建了一个表，根据门顶点连接的遍历面数量对Edgebreaker符号进行排序。这个编码模式代表了一种连接性预测方法，允许改进的熵编码。

Angle-Analyzer方案【Lee等人 2002】使用五个符号以平均1.5 bpv的速率编码流形三角网格的连接性。选择下一个处理的面，以尽可能保持已征服和未征服区域之间的边界为凸形。Lee和Park【2005】后来展示，通过使用基于连续门之间角度的算术编码器上下文，这一速率可以略有降低。

##### 3.1.5 阀值编码

流形三角网格包含的顶点数量大约是三角形数量的一半。因此，专注于插入新顶点并生成一个符号来描述其局部连接性的算法会比三角形遍历方法生成更少的符号。因此，如果每个符号的熵不比两倍大，这种算法将导致更好的连接性压缩性能。一种描述顶点连接性的方法是编码其阀值。

开创性的阀值驱动方法是Touma和Gotsman【1998】的算法。其原理是考虑由初始三角形形成的边界，并通过迭代添加相邻顶点来扩展该边界。连接性通过插入顶点的阀值来编码，通常集中在六个左右。因此，生成的顶点阀值列表可以通过熵编码器（2.3 bpv）高效压缩。它仍被视为最有效的连接性压缩方法之一。Alliez和Desbrun【2001b】后来提出了一些修改，以进一步降低压缩率。他们还证明，对于具有最大化熵的网格，其方法获得的压缩率与Tutte熵【Tutte 1962】匹配（见第3.1.2节）。因此，他们声称已经证明了基于阀值的方法的最优性。

FreeLence编码器【Kalberer等人 2005】采用了一种稍有不同的方法。它不是直接编码顶点的阀值，而是编码处理顶点的未征服边的数量。这种方法与几何驱动的网格遍历相结合，以保持活动列表尽可能凸，与Angle-Analyzer编码器类似【Lee等人 2002】。该算法在流形三角网格连接性压缩方面比Alliez和Desbrun【2001b】方法平均提高了35%。

##### 3.1.6 拓扑扩展

许多之前介绍的算法不接受任何拓扑作为输入。因此，拓扑算法【Taubin和Rossignac 1998】首先假定一个无边界的属0流形导向三角网格。作者随后提出了一些预处理和一些额外的信息编码，以消除属0和无边界的条件。Cut-Border Machine【Gumhold和Straßer 1998】和Touma和Gotsman的阀值方法【Touma和Gotsman 1998】可以处理带有边界和任意属的流形三角网格。对于Cut-Border Machine，提出了一种扩展，通过为某些操作编码额外的位来处理非定向网格。Mamou等人【2009】提出了一种扩展的阀值方法，用于编码非流形和非定向三角网格。该算法将三角网格划分为一组三角扇。对于每个扇，编码的信息主要是其10种配置码及其度数。Edgebreaker算法的第一个版本【Rossignac 1999】以属0流形三角网格为输入，但Lopes等人【2002】消除了属的限制。其方案编码额外的符号，以描述如何将输入网格变为单边界环网格。

##### 3.1.7 压缩多边形网格

三角形是网格中最常见的面类型，但并不是唯一的类型。具有更高面度的网格也有兴趣表示某些表面。前述方法不能直接应用于多边形网格，因为它们假设网格面度为三，以减少编码信息量。初步三角化允许使用限于三角网格的算法压缩多边形网格。然而，这种方法不能恢复初始连接性，并可能导致更高的压缩率，因为必须添加边。因此，多边形网格的压缩也在文献中被研究。

King等人【1999】的算法推广了Edgebreaker算法【Rossignac 1999；Rossignac和Szymczak 1999】，允许压缩四边形和四三角网格连接性。其原理是将每个四边形拆分为同一Edgebreaker遍历序列上的两个三角形。这导致高效的连接性压缩（对于四边形网格为0.25到0.85 bpv，对于四三角网格为0.78到1.14），因为某些Edgebreaker算法的组合变得不可能。论文还解释了如何以5 bpv的保证成本压缩多边形网格。

Face Fixer算法【Isenburg和Snoeyink 2000a】使用网格的面遍历压缩流形多边形网格的连接性。编码器生成每条边一个符号。实验结果显示，连接性压缩率范围为1.7到2.9 bpv。Kronrod和Gotsman【2000】的连接性编码器编码网格每个面的度及其与活动边界的关系。作者报告其方法略低于Isenburg和Snoeyink【2000a】的方法，但更易于描述和实现。Isenburg【2002】和Khodakovsky等人【2002】独立提出了基于阀值的方法，用于编码流形多边形网格的连接性。受Touma和Gotsman【1998】工作的启发，这些方法通过网格的面遍历编码顶点和

##### 3.1.8 压缩体网格

当应用需要网格化一个体积的内部时，必须使用体网格。它们包含比表面网格更多的信息来定义单元。因此，压缩它们也很有意义。

Szymczak 和 Rossignac【1999】提出了一种**生成树方法**，以大约每个四面体7比特的速率编码四面体网格。压缩格式由四面体生成树字符串和折叠生成树组成。第二个树编码了恢复初始网格所需的四面体生成树边的折叠操作。Gumhold 等人【1999】提出了一种基于原始 Cut-Border Machine【Gumhold 和 Straßer 1998】的边界扩展方法。但在这里，边界不是由边组成的曲线，而是由三角形组成的表面。十种不同的符号编码连接性。测试模型的连接性压缩率低于每个四面体2.4比特。

Isenburg 和 Alliez【2002a】研究了使用阀值驱动方法压缩六面体体积网格。他们的方案在迭代遍历所有网格六面体期间编码网格边的度数及其连接的面数。对测试模型获得的平均压缩率为每个六面体1.5比特。Krivograd 等人【2008】的六面体网格连接性压缩器首先压缩网格边界，然后用六种不同的符号和顶点度数压缩网格内部。实验结果表明，与 Isenburg 和 Alliez【2002a】的方案相比，这种方法在处理低属大网格时压缩率高达50%。

Lindstrom 和 Isenburg【2008】提出了一种原始的方法来压缩六面体网格连接性。他们的方法从输入文件索引数据结构中编码顶点索引。在这个文件中，六面体由一个包含八列顶点索引的表描述。其原理是独立压缩表的每一列。确实，如果顶点是有序排列的，少量索引的上下文可以准确预测下一个值。然后用字节对齐的变长编码对预测残差进行编码。获得的字符串随后由标准的 gzip 数据压缩算法压缩。即使该算法不如最先进的方法高效，但它有许多优点。其中，它快速且内存高效。它无需任何适应即可处理非流形网格。它易于实现：不需要任何特定的网格数据结构，并且大量依赖于自由可用的数据压缩算法 gzip。

Prat 等人【2005】描述了一种通用算法，用于压缩任何种类的流形网格（表面或体积，是否可定向，具有任意面或单元度数）的连接性。他们的方案基于一种通用地图数据结构，包含一种称为飞镖的原始元素类型。存储这些元素之间的连接关系，称为 involutions。即使这种方法在压缩率方面不如专门的方法具有竞争力，但其主要优点是其通用性。在网格类型可能变化的情况下，处理不同类型网格的能力是一大优势。

还提出了一些3D规则网格压缩的方法，也称为体素压缩。对于低维网格化数据（例如图像和视频），已经有多种压缩方法应用于体积数据，例如矢量量化【Ning 和 Hesselink 1992】，离散余弦变换（DCT）【Yeo 和 Liu 1995；Lum 等人 2002】，离散傅里叶变换（DFT）【Chiueh 等人 1997】，游程编码（RLE）【Anagnostou 等人 2000】，或小波【Muraki 1992；Guthe 和 Straßer 2001；Bajaj 等人 2001；Rodler 1999】。这些方法都是有损压缩方案。在 Fowler 和 Yagel【1995】中，作者提出了第一个基于预测的体素数据无损压缩方案。同样在 Ibarria 等人【2003】中，引入了 Lorenzo 预测器用于压缩n维标量场。

### 3.2 几何压缩

网格几何压缩（即顶点坐标的压缩）非常重要，因为在大多数情况下，它的体积大于连接信息。通常，网格几何的压缩始于对所有顶点坐标的量化。然后，在每次压缩迭代中，通过已编码邻居的位置预测编码顶点的位置。如果预测准确，则预测误差较小，因此可以高效地进行熵编码。本节提供的压缩率仅涉及几何数据。

#### 3.2.1 量化

在输入文件或计算机内存中，顶点坐标通常由三个 IEEE 32 位浮点数表示。这种表示提供的精度对于大多数应用来说是不必要的。量化可以显著减少需要编码的数据量，而不会出现明显的质量损失。

标量量化将浮点数的位置转换为整数位置。网格的包围盒被划分为一个3D网格。每个轴的单元数取决于可以用量化比特编码的最大整数。每个单元的大小可以是均匀的或不均匀的。网格的每个顶点被移动到它所属的单元的中心。然后，整数位置由单元的三个索引坐标组成。

大多数与之前描述的知名连接性压缩方案【Deering 1995；Taubin 和 Rossignac 1998；Rossignac 1999；Touma 和 Gotsman 1998】配套的几何编码器使用均匀标量量化。量化比特的数量通常在8到16之间。由于此方法，网格几何会略微改变，而连接性保持不变。

Bajaj 等人【1999b】和 Lee 等人【2002】提出了用三个角度编码顶点位置的方法。对于角度分析编码器【Lee 等人 2002】，计算了两个内角和一个二面角。量化不是在全局顶点坐标上进行，而是在这些局部角度上进行。通过对不同角度应用不同的量化，这种方法可以实现更好的率失真性能。Lee 和 Park【2005】提出将顶点定位在四个不同的范围大小中，因为他们注意到很少有顶点位于最大的范围内。为了编码顶点在范围内的位置，根据范围的大小，范围被更多或更少地细分。顶点的位置因此通过范围的类型和子单元编号进行编码。

向量量化是一种替代技术，它将要量化的点集划分为任意形状的组。量化单元不再是长方体。它们的形状可以更好地适应数据。每组都有一个代表点。这些点构成了必须与压缩数据一起保存的代码本。向量量化在实验中已证明其能够实现比标量量化更好的率失真性能【Lee 和 Ko 2000；Chou 和 Meng 2002；Bayazit 等人 2007；Lu 和 Li 2008；Meng 等人 2010】。然而，量化单元的确定可能会导致计算密集型工作。

#### 3.2.2 预测

最早的网格压缩方法【Deering 1995；Chow 1997】仅使用增量预测。预测下一个要编码的顶点的位置为前一个顶点的位置。增量，即两个位置之间的向量，然后进行编码。Bajaj 等人【1999b】使用了二阶预测器，该预测器编码连续增量预测之间的差异。

拓扑手术算法【Taubin 和 Rossignac 1998】使用线性预测。预测下一个要编码的顶点的位置为顶点生成树中前 K 个顶点的线性组合。线性函数的 K 个参数最小化网格上的均方预测误差。这些值被存储在压缩文件中，以便解码器可以使用。

除了基于阀值的连接性编码外，Touma 和 Gotsman【1998】还引入了平行四边形预测。与基于阀值的连接性编码一样，平行四边形预测是许多后续方案的基础思想。压缩算法通过一个边的三角形引入一个新顶点。新顶点的预测位置与两个边顶点和对角三角形的第三个顶点形成一个平行四边形（见图6(a)）。实验结果表明，三角网格几何可以以大约8.5比特/顶点的压缩率进行压缩，量化为8位。

双平行四边形预测【Sim 等人 2003】在可能的情况下使用由两个平行四边形预测给出的平均位置（见图6(b)）。双平行四边形在约75%的情况下可以使用。这比平行四边形预测略有改进。

Isenburg 和 Alliez【2002b】表明，平行四边形预测也可以用于任意面度数的多边形网格的几何压缩。Isenburg 等人【2005a】稍后提出了一种对任意多边形的平行四边形预测的泛化。多边形的缺失顶点位置通过对不同度数和已知顶点的多边形计算的权重进行预测。这些权重来自多边形的傅里叶分解，其中最高频率设置为零以确保多边形形状良好。

FreeLence 编码器【Kalberer 等人 2005】使用三种平行四边形预测的组合来编码三角网格的几何：两个标准的预测以及一个新应用于连接两个外部顶点的虚拟边的预测（见图6(c)）。

Cohen-Or 等人【2002】引入了多路预测。其原理是基于已编码的顶点，用尽可能多的平行四边形预测来预测新顶点的位置。

Gumhold 和 Amjoun【2003】的几何预测器尽可能多地执行平行四边形预测以确定预测的切向分量。然而，为了估计法向分量，编码器通过拟合高阶曲面到已编码的几何部分来进行估计。预测位置因此在高阶曲面与切向分量定义的圆的交点处。Ahn 等人【2006】也使用尽可能多的平行四边形预测。此外，他们添加了自己的二面角预测方案，该方案对所有相邻的二面角进行平均。

最近，Vaša 和 Brunnett【2013】提出了加权平行四边形预测方法，其中权重是根据顶点的阀值计算的。三种提出的权重计算方法具有递增的计算成本。实验结果报告称，残差的计算香农熵比标准平行四边形预测低20%。

Courbet 和 Hudelot【2011】使用泰勒展开来确定各种预测模板的预测权重。这种方法允许理论上确定平行四边形预测的最佳权重。结果证明，FreeLence 权重【Kalberer 等人 2005】优于双平行四边形预测权重【Sim 等人 2003】，并为多边形预测【Isenburg 等人 2005a】确定了更好的权重。

关于体积网格，Gumhold 等人【1999】使用增量编码来编码四面体网格的几何。Isenburg 和 Alliez【2002a】用内外平行四边形预测压缩六面体网格的几何。

#### 3.2.3 几何驱动压缩

对于压缩网格，几何信息的大小通常优于连接信息的大小。然而，对于大多数算法，编码是由网格连接性驱动的。因此，研究了在连接性之前专注于几何编码的想法。

Kronrod 和 Gotsman【2002】设计了一种压缩方案，其中网格编码由几何驱动。这种方法构建了一个网格覆盖树，其中包含网格的所有顶点。该树定义了网格顶点的特定遍历，以最小化每个顶点位置所需的平行四边形预测误差。几何压缩效率提高了多达50%，代价是连接性压缩率略高。这种方法特别有利于CAD模型，这些模型通常具有不光滑的几何。

Chen 等人【2005】的四面体网格压缩方案也由几何驱动。它试图构建一个最佳遍历树，以最小化新顶点位置的预测误差。所使用的预测器是四面体网格的平行四边形预测的泛化。

Shikhare 等人【2001】将几何驱动压缩的理念推进了一步。他们的方案试图在3D模型中找到重复的几何模式。识别的模式可以是组件、组件内的区域或跨组件的区域。这种方法特别有利于大型 CAD 或数字遗产模型。Cai 等人【2009】后来提出

了一个类似的方案，取得了略微更好的性能。他们包括了对重复模式的缩放变换。

先前方案的连接性编码是由网格几何驱动的。然而，网格几何和连接性是同时压缩的，其数据在压缩流中交错。Lewiner 等人【2006】提出了一种替代的几何驱动编码技术。网格几何首先完全独立于连接性进行压缩，通过编码量化空间的 kd-tree 分解。然后，表面重建算法通过选择新的顶点来迭代地将新三角形附加到网格的边界。对候选顶点的引用被编码。该算法可以压缩任何类型的三角网格。这种方法对于四面体网格的压缩非常具有竞争力【Lewiner 等人 2006】，与 Grow & Fold【Szymczak 和 Rossignac 1999】和流式【Isenburg 等人 2006】方法相比。

在类似的思路中，Chaine 等人【2009】提出了一种基于表面重建的网格连接性压缩方案。在解压缩时，该技术假设几何已经被解码。对于编码和解码，生成了一个从点集生成的 Delaunay 三角剖分。然后，变换算法恢复输入网格的初始连接性。因此，采用类似技术生成的网格的连接性以非常低的成本进行编码。

#### 3.2.4 压缩浮点位置

如前所述，大多数网格压缩算法会对顶点坐标进行量化。但某些应用可能要求浮点坐标的精确恢复。Isenburg 等人【2005b】研究了浮点几何的无损压缩。浮点坐标被分解为符号、指数和尾数分量。这些分量的预测误差在不同的算术上下文中独立压缩。该方法能够以大约 35 比特/顶点的速率压缩网格几何。

### 3.3 处理大型网格

一些模型过于庞大，无法完全加载到计算机的主内存中。因此，为了压缩这些模型，设计了出核（out-of-core）方案。这些方案会动态加载和卸载网格的不同部分，具体取决于当前处理的网格区域。

#### 3.3.1 分区和块压缩

Ho 等人【2001】提出了对输入模型进行分区的方案。每个部分在内核中独立压缩。Edgebreaker 压缩算法【Rossignac 1999】用于连接性的压缩。在解压缩过程中，额外的符号被集成以将各部分拼接在一起。对于几何压缩，使用了平行四边形预测【Touma 和 Gotsman 1998】。类似地，Ueng【2003】提出了通过将大规模四面体网格划分为基于几何的八叉树数据结构中的块（称为 octan）来压缩连接性。每个 octan 通过编码四面体条带在内核中进行压缩。

Isenburg 和 Gumhold【2003】提出了一种用于大型多边形网格压缩的出核网格数据结构。该数据结构基于输入网格的分段构建。然而，与之前的出核方法不同，簇是与流式处理方法一起压缩的。在压缩过程中，数据结构动态加载处于 Touma 和 Gotsman 编码器【1998】的活动列表中的网格簇，并在不再需要时卸载它们。解压缩时，内存占用很小，仅由活动列表组成。作者声称，获得的压缩率大约低25%，解压速度比 Ho 等人【2001】的方案快约100倍。

#### 3.3.2 流式处理格式

在流式处理方法的基础上，Isenburg 和 Lindstrom【2005】提出了一种通用的 I/O 高效流式格式用于网格。该格式将索引三角形和顶点与额外信息交织在一起，描述何时引入和完成网格元素。因此，应用程序只需保留当前处理的小部分网格在内存中。作者提出了几种策略，用于重新排序网格的索引，以便与流式处理兼容。

这一框架成为了多个流式压缩技术的基础，如 Isenburg 等人【2005c】针对三角网格的技术、Isenburg 等人【2006】针对四面体网格的技术以及 Courbet 和 Isenburg【2010】针对六面体网格的技术。与非流式方法相比，这些技术的几何压缩率通常相当，但连接性压缩率较差。然而，流式处理方法的 I/O 效率使得它们能够快速压缩大型网格，内存占用非常低。

#### 3.3.3 Tetstreamer 算法

Tetstreamer 算法【Bischoff 和 Rossignac 2005】是为客户端-服务器可视化目的设计的，也遵循了流式处理策略。服务器以从后到前的可见性顺序压缩并发送四面体网格到客户端。输入网格被分解为称为 sheets 的表面层，这些层由 Edgebreaker 算法【Rossignac 1999】进行压缩。客户端还接收到一个位流，指示如何将每个四面体附加到当前的 sheet。四面体网格的连接性平均压缩为每个四面体 1.7 位。

### 3.4 压缩与重新网格化

大多数压缩方案不会改变网格的连接性。然而，一些应用程序在解压缩后不需要恢复初始连接性。在这种情况下，通过利用这一新的自由度，可以进一步提高压缩率。

#### 3.4.1 重新网格化算法

Szymczak 等人【2002】提出了一种重新网格化算法，生成逐片正则网格。输入网格首先被分段为称为 reliefs 的近似平坦区域。每个 relief 属于六种不同的方向之一。然后，这些区域在由三组平行线定义的正则六边形网格上重新采样。所有原始顶点，除了边界顶点，都被合并。一个拼接算法形成了一个封闭网格。该方案与针对正则网格优化的 Edgebreaker 压缩算法一起用于连接性。SwingWrapper 方案【Attene 等人 2003】也生成半正则网格。它旨在生成等腰三角形，以便在插入的顶点由 Edgebreaker 编码器编码时，只需编码一个量化的二面角。这两种方法都利用生成网格的高正则性来进行高效压缩（Szymczak 等人【2002】平均总压缩率为每顶点 4 位，Attene 等人【2003】几何压缩率为每顶点 6 位）。

#### 3.4.2 网格简化

网格简化也可以视为一种有损压缩，因为它减少了连接性和几何信息。虽然对网格简化方法的详细回顾超出了本文的范围，但有兴趣的读者可以参阅 Cignoni 等人【1998】的综述文章。

#### 3.4.3 表格总结

表 I 总结了我们认为最相关和开创性的单一率压缩方法。

### 4. 最新进展：渐进网格压缩

渐进算法使得用户可以快速显示网格的粗略版本，然后随着更多数据的解压缩，逐步细化网格，直到恢复初始模型。连接性保持方案在解压缩过程中恢复输入模型的连接性，而忽略连接性的方案则通过重新网格化来编码输入模型，以实现更高的压缩性能。

#### 4.1 连接性保持方案

##### 4.1.1 顶点分裂与边缘合并

Hoppe【1996】首次引入了渐进网格的概念。其思想是使用边缘合并操作（图7）逐步简化网格，并通过优化过程最小化能量函数。压缩表示包括基础网格以及所有用于增量反向操作（称为顶点分裂）的参数。Hoppe 通过存储顶点的索引和大约 5 位来编码顶点分裂的连接性（见图7）。几何编码方面，顶点位置被全局量化，并通过 delta 预测进行编码。这种方案的主要优点是具有高多分辨率粒度，并且可以在解码期间执行选择性细化。虽然这种粒度达到了，但压缩率较低，通常为 37 bpv（10 位量化）。Popovic 和 Hoppe【1997】将渐进网格表示扩展到任意的单纯形复合体。主要贡献是引入了广义的顶点分裂（及其对应的顶点统一），允许在细节层次上进行拓扑变化，这些细节层次可能由 2-，1- 和 0- 简单形（即三角形、边和顶点）组成。为了保持细节层次的良好可视化，1- 和 0- 简单形被用合适的圆柱体和球体进行近似。

为了更接近单一率方法的压缩率，一些方法被提出来批量编码顶点分裂操作。Taubin 等人【1998】建立了一种渐进网格压缩方案，受单一率拓扑手术算法【Taubin 和 Rossignac 1998】的启发。他们的渐进森林分裂表示编码了一个流形三角网格，包含一个基础网格和一系列森林分裂操作。连接性通过标记切割边和孔的重新三角化方式进行编码。

Pajarola 和 Rossignac【2000】建议尽可能多地执行边缘合并操作以生成新的细节层次。然后，通过在网格上构建一个顶点跨度树来编码顶点分裂，并保存每个分裂顶点和切割边。顶点位置被均匀量化，但 Li 等人【2006】后来证明，使用向量量化（见 3.2.1 节）可以提高算法的率失真性能。Karni 等人【2002】将这一方案适配成一种渐进压缩方案，使所有细节层次的快速渲染成为可能，使用顶点缓冲区。顶点缓冲区是图形硬件制造商为通过通用三角带加速渲染而引入的。提出的算法的第一步是创建一个高效的顶点渲染序列，由一系列相邻顶点组成。然后，沿着这个序列简化网格。

这些方法的压缩比率更高（Taubin 等人【1998】约 30 bpv，Pajarola 和 Rossignac【2000】约 22 bpv，10 位量化）。尽管如此，其多分辨率粒度仍低于渐进网格表示。

##### 4.1.2 顶点移除

其他渐进压缩方案使用顶点移除代替边缘合并。Li 和 Kuo【1998b】开创了一种基于顶点移除的方案，之后进行局部补丁重新三角化。连接性通过局部索引进行编码，该索引指定补丁模式和一个全局索引，该索引定位该模式在整个网格中的位置。几何数据通过重心误差预测进行编码。作者还首次提出了在传输细节层次时调整顶点量化的思想。Cohen-Or 等人【1999】使用相同的简化机制，但他们将顶点移除分组以生成离散的细节层次。生成新层次时，所有移除顶点的补丁必须是独立的。这些补丁通过给属于同一补丁的三角形分配相同的颜色来标识。通过这种方法，可以获得与单一率技术相当的竞争性压缩率（12 位量化下约 23 bpv）。Bajaj 等人【1999a】将其单一率分层方案【Bajaj 等人 1999b】扩展为包括渐进性。在连续简化步骤中，他们的算法从每层移除顶点，重新三角化，并编码拓扑变化。

Alliez 和 Desbrun【2001a】提出了一个可以视为 Touma-Gotsman 单一率编码器【Touma 和 Gotsman 1998】的渐进版本。在每次迭代中，网格通过两个确定性的网格遍历进行简化。简化征服（见图8 中的 a 到 b）移除 valence 小于或等于 6 的顶点（对于边界顶点，只有 valence 为 3 或 4 的顶点被移除）。然后，通过一种确定性的重新三角化策略填补产生的孔。在征服过程中，通过种子门的 FIFO 队列（蓝色箭头）来标记顶点是否需要增加或减少 valence（以获得尽可能规则的网格）。然后，为每个门提供一个表格，根据这些标志提供准确的三角化，并将准确的标志值传播到未标记的顶点。经过简化征服后，清理征服（见图8 中的 b 到 c）移除 valence 为 3 的顶点。网格连接性通过移除顶点的 valence 及一个 null 补丁代码来编码三角形，几何通过补丁重心误差预测在局部 Frenet 坐标系中进行编码。获得的压缩率约为 21 bpv（12 位量化）。

由于 valence 驱动的网格连接性编码在单一率和渐进网格压缩中已显示出其效率，原始的 Alliez-Desbrun 算法启发了许多改进其率失真性能的衍生方案。例如，Cheng 等人【2006】禁止在简化征服过程中移除某些顶点，这些顶点称为锚点，并通过其主曲率进行检测。实验表明，保持这些顶点在所有细节层次中可以提高率失真性能。Lee 等人【2012】通过使用自适应量化方法来提高 Alliez-Desbrun 编码器的率失真权衡。其思想是交替进行简化操作和全球量化操作，使用 Peng 和 Kuo【2005】的方法进行编码（见 4.1.3 节）。他们在 12 位量化下实现了约 1 bpv 的压缩率改进。

Ahn 等人【2011】优化了网格遍历，以最大化每个简化步骤中移除的顶点数。还使用了曲率预测来编码几何。这与谱方法（见 4.1.6 节）中的一般思想相似，因为基于拓扑的 Karhunen-Loeve 变换集中分布了几何残差。残差通过位平面编码器进行熵编码。简化征服与比特平面的传输交替进行，以提高率失真性能。他们显著提高了 Alliez-Desbrun 编码器的压缩率（12 位量化下减少约 4 bpv）。

Lee 等人【2011】通过引入两种新的预测方法显著提高了几何压缩（最高可达 60%）。双环预测旨在使一个顶点及其一环邻居顶点具有相同的重心预测。最小均方误差预测基于与预测顶点具有拓扑距离为 1 或 2 的顶点构建线性预测器。该算法首先通过基于网格连接性的算法对输入细节层次进行分段。然后，选择最有效的方法来编码每个簇。为了改进连接性编码，Kim 等人【2011】建议在解码过程中预测当前补丁插入顶点的 valence。通过几何信息，尝试每个补丁可能性对应的 valence 值。然后，通过测量生成三角形的规则性来对所有可能性进行排序。预测的可能性是规则性最高的那个。对于每个细节层次，还使用每种 valence 值的频率进行更好的预测。

##### 4.1.3. 基于几何的渐进网格压缩

与单率网格压缩（见第 3.2.3 节）类似，基于几何的渐进网格压缩也关注在连接性之前进行几何压缩的思想。

在 Gandoin 和 Devillers【2002】的方案中，顶点位置存储在 k-d 树中。初始单元沿三个轴逐次分裂，直到获得所需的几何精度。每次分裂时，编码一个子单元的顶点数量（见图 9）。连接性通过通用的顶点分裂和基于几何的预测机制进行编码。

Peng 和 Kuo【2005】还开发了一种基于八叉树数据结构的几何驱动渐进网格压缩算法。在细分后，他们没有像 Gandoin 和 Devillers【2002】那样编码每个单元内的顶点数量，而是编码非空子单元的数量。然后，邻接顶点允许预测哪些单元可能是非空的。通过优先细分重要单元，速率-失真性能得到了改进。网格的连接性通过顶点拆分进行编码。编码了与两个由拆分生成的顶点（称为主顶点）连接的顶点数量。然后，基于几何的预测算法确定最可能的候选者。三角网格在 12 位量化下的压缩率约为 15 bpv。Tian 等人【2012】后来提出了一种替代方法，根据光滑度度量预测非空单元。他们还根据代表顶点的度数对单元进行排名，以决定细分顺序。

这些基于空间细分的渐进压缩方法的一个优势是它们可以压缩任意简单复合体。此外，它们在流形网格上实现了高效的压缩率。然而，由于低量化，其速率-失真性能在低速率下表现较差。不允许对重要顶点的移除进行控制。与基于连接性的引导方法不同，网格简化不能使用度量进行驱动。

波形框架传统上用于半规则连接性网格，如第 4.2.1 节所述，但 Valette 等人【2004a】提出了一种子划分方案，可以生成不规则网格。他们随后基于这一框架构建了渐进网格压缩算法：Wavemesh【Valette 和 Prost 2004b】。初始网格通过为不规则网格量身定制的子划分方案逐步简化。连接性数据由所有面子划分操作组成。一个三角形面可以被划分为四个、三个或两个面，或者保持不变。连接性通过三种数据类型编码，如图 10 所示。几何通过波形提升方案进行编码。插入顶点的位置被预测为其父边缘的中点。获得的压缩率稍好于 Alliez 和 Desbrun【2001a】的方案（使用 12 位量化，约 19 bpv）。

Lee 等人【2013】将原始 Wavemesh 方案的压缩性能提高了 16.9%。为了改善连接性编码，他们提出了基于高斯混合概率模型的方法，以预测插入的顶点、面方向和边翻转。对于几何编码，他们将细节层次的新顶点分为三组。为了编码后续组的顶点位置，编码器使用已编码组的位置。顶点位置使用 Lee 等人【2011】的双环预测方案进行预测。残差在局部坐标系中编码，类似于 Alliez 和 Desbrun【2001a】的方法，使用比特平面编码器进行编码。

##### 4.1.5. 通过重建进行渐进压缩

Valette 等人【2009】将渐进网格压缩问题视为网格生成问题，在他们的增量参数化细化框架中解决。编码器从 Garland 和 Heckbert【1997】的简化方案生成的粗略网格开始。基网格通过分裂最长边逐步细化。插入顶点的位置对应于原始网格的一个顶点。位置进行自适应量化。量化位数取决于细化的级别。在每次细化步骤中，通过边翻转来修改三角剖分，以满足局部 Delaunay 属性或修复连接性漂移。这一过程在图 11 中进行了总结。当所有原始网格的顶点都被插入后，通过根据翻转距离启发式指导的边翻转恢复初始连接性。编码每条边一个比特，以说明是否需要翻转。这种算法已知压缩效率高（使用 12 位量化，约 15 bpv），并且具有良好的速率失真性能。然而，完整的连接性恢复过程不能保证成功。

计算初始网格的最佳简化版本的思想最近在 Peng 等人【2010】中得到了进一步研究。该算法从初始网格顶点集开始，使用广义 Lloyd 算法【Lloyd 1982】递归地将其分割成多个子集。每次生成新顶点子集时，选择一个代表顶点，使其接近子集的几何中心并具有高曲率。在该层次结构中，子集的数量被编码。代表顶点与其父代表顶点之间的偏移在圆柱坐标系中预测并自适应量化。通过顶点拆分和主顶点预测编码连接性。该算法在 12 位量化下的压缩率约为 16 bpv。

##### 4.1.6. 使用拉普拉斯算子的几何压缩

傅里叶分析通常用于声音和图像压缩。将数据投影到频域并编码低频信号，通常可以在解压缩时以较少的数据恢复原始信号的高质量近似。Karni 和 Gotsman【2000】提出将这一技术应用于网格顶点位置的压缩。为了将坐标从空间域投影到频域，编码器使用网格的拉普拉斯算子。拉普拉斯矩阵的特征向量形成 Rn 的正交基，其相关特征值被认为是频率。每个坐标分量向量在基向量上的投影即为网格频谱。基本原理是，如果几何体足够光滑，其频谱将集中在低频。因此，低频的光谱系数在量化和熵编码后，足以构建初始网格的良好近似。实际上，光谱压缩具有优秀的速率失真性能。顺便提一下，Ben-Chen 和 Gotsman【2005】证明，对于某些几何网格模型类别，光谱压缩是最优的，因为它等同于这些类别上的主成分分析（PCA）。Mahadevan【2007】用扩散小波基替代了拉普拉斯基，并展示了其在用相同数量的基函数表示输入网格方面的能力。

由于特征向量分解是一个高复杂度操作（O(n^3)），Karni 和 Gotsman【2000】将网格分割为约 500 个顶点的区域。虽然计算变得可行，但仍然非常繁重。之后的方法【Karni 和 Gotsman 2001】提出使用固定基于规则连接性映射到网格的不规则连接性上。希望平均能量仍集中在低频。尽管压缩效率降低，但解压缩加速，因为不再计算特征向量分解。Bayazit 等人【2010】减少了映射方法的计算复杂度。他们还使用了比特平面编码器进行光谱系数编码。Cayre 等人【2003】展示了通过引入分段区域之间的重叠，可以获得速率失真增益。

Mamou 等人【2010】设计了一种替代算法，计算网格的拉普拉斯矩阵。然后通过求解具有最小控制点集的热方程来近似网格。顶点位置被编码为热方程给出的近似值的残差。连接性通过 Touma 和 Gotsman【1998】的单率编码器进行编码。该方案实现了极佳的压缩比（使用 12 位量化，约 10 bpv）。然而，由于求解热方程的高复杂度，这是一个显著的缺点。

##### 4.1.7. 多边形网格

前面描述的大多数方法仅能压缩三角网格。对于其中一些，提出了简单的扩展以压缩具有任意面度的网格。初步三角剖分允许使用现有的方法压缩多边形网格，这些方法限制于三角网格。然后，需要编码额外的数据以在解压缩后恢复初始连接性。Taubin 等人【1998】采用这种方法扩展了渐进森林分割算法。Li 等人【1998b】表示他们的压缩方案也可以用于多边形网格，但没有提供如何调整算法的细节。在更近期的工作中，Peng 和 Kuo【2005】注意到，由于他们的八叉树编码器可以压缩任意连接性之间的顶点，可以修改面构建算法以重建多边形面，每个拆分需要额外的两位信息。

Maglo 等人【2012】的编码器专门设计用于渐进编码多边形网格。通过补丁简化操作生成连续的细节层次，该操作移除补丁中心顶点并局部重新网格。网格连接性通过两个布尔符号列表进行编码：一个用于插入的边，另一个用于移除中心顶点的面。网格几何通过移除顶点坐标的重心误差预测进行编码。该方案在压缩三角网格方面仍具有竞争力。

##### 4.1.8. 体积网格

据我们所知，对于体积网格的渐进压缩，提出的工作非常有限。Pajarola 等人【1999】设计了一种渐进压缩算法，用于四面体网格的连接性。为了生成细节层次，执行一批独立的边收缩。连接性通过标记必须在解压缩期间拆分的顶点，并识别围绕拆分顶点的切割面进行编码。另一种方法可以使用几何驱动的方法【Gandoin 和 Devillers 2002；Peng 和 Kuo 2005】（见第 4.1.3 节），因为它们可以压缩任意的简单复合体。然而，它们没有集成单元的概念。

### 4.2. 连接性无关方案

与单率网格压缩（见第 3.4 节）类似，当恢复初始网格连接性不是至关重要时，使用重新网格化方法可以进一步降低压缩率。

#### 4.2.1. 半规则网格的波形变换

在一般情况下，基于波形变换的渐进网格压缩方案从输入网格的粗略不规则版本开始，然后通过生成半规则网格的细分方案逐步精化。在每次细分后，顶点会被移动以尽量减少细分模型与输入网格之间的失真。这些 delta 位移，即波形系数，随后被编码。通常使用 Loop 的细分 [Loop 1987] 或蝴蝶细分 [Dyn 等 1990] 进行此操作。

在图像编码中，波形表示被认为可以有效地去相关原始数据。因此，Khodakovsky 等人【2000】提出使用波形变换来压缩任意拓扑的表面。然而，这种压缩方案无法编码任何连接性。使用 MAPS 算法 [Lee 等 1998] 对输入模型进行重新网格化。基于 Loop 的细分 [Loop 1987] 的波形变换将原始网格替换为最粗糙的不规则网格和表示连续半规则细节级别之间差异的波形系数序列。波形系数在局部框架中表示，并通过零树编码器进行编码。该方案后来得到了改进【Khodakovsky 和 Guskov 2003】。这种改进采用了标准网格表示【Guskov 等 2000】。这种波形分解的详细系数在可能的情况下只包含一个法线分量（超过 90% 的情况下），而不是标准细分的三个系数。由于需要编码的波形系数从三个减少到一个，法线网格压缩提供了显著更好的压缩比。

Payan 和 Antonini【2002, 2005, 2006】在标准和法线网格表示的波形子带上分配位，以改善速率-失真性能。提出的优化框架通过变化波形系数的量化来最小化全局重建误差。为了改善法线网格的压缩，Lavu 等人【2003】基于之前在邻域中编码的值局部优化法线分量的量化。Kammoun 等人【2012】提出优化基于提升的波形变换（蝴蝶和 Loop）的预测方案。对每个细节级别，计算预测器的最佳参数以最小化详细系数的集合。实验结果表明，与经典波形分解相比，均方根失真略有减少（约 2%），速率相似。Chourou 等人【2008】 resorted to mesh segmentation 以优化每个生成集群的波形算子。提升方案预测步骤的参数选择以最小化详细系数的方差。Zhao 等人【2011】基于矩阵值的 Loop 的细分进行了压缩方案，以更好地控制形状。Denis 等人【2010】利用了子带和复合波形系数之间的统计依赖关系，以确定最佳量化器。

Chen 等人【2008】提出通过定期重新网格化为四边形来压缩输入表面。四边形细分将每个面分裂成四个新面，插入一个顶点。波形分解通过提升方案进行制定。零树编码也用于编码系数。

其他使用波形变换的网格方法专注于移动解压 [Ma 等 2009] 和支持有损传输 [Luo 和 Zheng 2008]。这些方法的理念是减少解压所需的计算量，并使用错误保护技术以适应移动能力和有损网络。

由于基于波形的压缩方案依赖于重新网格化，因此实际上很难给出压缩模型的绝对压缩率。实际上，几何（即使使用固定量化）或连接性在解压过程中都没有恢复。然而，总体而言，基于波形的算法提供了显著优于其无损对等物的速率-失真性能。

#### 4.2.2. 几何图像

几何图像【Gu 等 2002】是一种原创的方法，用于通过波形图像压缩方案压缩流形网格。为了在规则的二维网格上重新采样输入模型，首先将网格切割成同胚于圆盘的形式。然后，一个将切割网格的点映射到单位正方形的参数化函数允许计算图像中每个像素的 xyz 值。在解压过程中，几何图像像素用于构建原始网格的三角网格近似。然而，有损压缩会导致沿表面切口的“裂缝”。Hoppe 和 Praun【2005】后来提出通过使用球面重新网格化方法构建几何图像。为了将球体展开到几何图像上，他们提出了一种基于规则八面体域的方案和另一种基于展平八面体域的方案。这些域的几何形状非常适合使用球面波形，从而避免了边界重建问题。

Shi 等人【2012】改进了法线图像的压缩，因为它们通常由于高变化而更难压缩。他们的框架利用了法线图像、几何图像和法线图像的三个分量之间的相关性。Sander 等人【2003】将表面分片映射到多个图表上，以减少失真。Peyre 和 Mallat【2005】研究了用 bandelets 压缩几何图像。bandelet 化的目的是去除高幅度波形系数之间的相关性。实验结果表明，在类似速率下，失真可以减少约 1.5 dB。

Mamou 等人【2010】提出了一种基于 b-splines 和几何图像的渐进网格压缩方法。在对输入网格进行分割后，每个补丁被参数化并由 b-spline 曲面近似。b-spline 控制点被量化并编码成三个灰度几何图像（每个轴一个），使用渐进 JPEG 2000 编码器。补丁的连接性使用 Touma 和 Gotsman【1998】的算法进行无损编码。额外的编码信息允许恢复补丁邻接关系。

Ochotta 和 Saupe【2008】提出了一种替代的基于图像的表面压缩方法。首先对输入网格进行分区。然后，将每个区域投影到平面上。结果的高度场被转换为图像，并使用自适应波形编码器进行压缩。在解压后，将分区拼接以生成封闭网格。获得的实验结果类似于 Guskov 等人【2000】的法线网格方法的结果。

表 II 总结了最重要和开创性的方法。“Prog. Granularity”列表示渐进的粒度（从 1 到 5），表示在增加细节级别时添加的新元素数量。最高粒度由 Hoppe【1996】的渐进算法获得，每个细节级别添加一个顶点。较低的粒度适用于 Wavemesh【Valette 和 Prost 2004b】，它生成较少的细节级别（即，因为每个细化级别添加了许多元素）。

### 5. 现有的随机访问网格压缩技术

单率和渐进网格压缩算法的一个问题是，当用户希望访问一个非常大的网格的特定部分时，必须下载并解压整个模型。随机访问算法允许仅解压所需的部分。一些算法仅提供对网格的原始细节级别的访问，但其他算法允许以不同的细节级别解压不同的部分。

#### 5.1. 随机访问压缩

##### 5.1.1. 基于集群的随机访问压缩

Choe 等人【2004, 2009】的算法首先使用 Lloyd【1982】的方法对输入网格进行分段。生成的图表旨在是平面且紧凑，以实现高压缩比。该编解码器的重要特点是每个图表都使用单率角度分析编码器【Lee 等 2002】独立压缩。为了避免边界顶点的几何信息在两个图表之间的重复，它们的位置在称为“线”的序列中独立压缩。下一个待编码线顶点的位置通过两个之前编码的位置的线性组合进行预测。集群之间的连接性以多边形网格的形式进行编码，采用 Khodakovsky 等人【2002】提出的编码方案。图 12 说明了这一压缩方案。

Chen 等人【2008】使用了一种生成有意义区域的分段算法。每个集群随后使用 Edgebreaker 算法【Rossignac 1999】进行压缩。与 Choe 等人【2004】的不同之处在于，集群之间的边界是三角带而不是线。这些三角带也由 Edgebreaker 算法压缩，但边界数据中没有嵌入几何信息。顶点位置在每个集群内部进行编码。

Yoon 和 Lindstrom【2007】也构建了一个基于集群的随机访问压缩方案。他们将随机访问支持添加到流式网格压缩【Isenburg 等 2005c】中。网格通过在缓存无关布局中顺序访问和分组网格三角形和顶点进行压缩。每个集群由固定数量的三角形（几千个）组成，并使用流式网格压缩方案独立压缩。边界顶点的几何信息不会重复：它在一个集群中编码一次，并在其他集群中引用。该方案提供了一个网格访问编程接口，允许以低计算成本通过标识符访问网格的任何元素。实验结果报告了比标准流式网格压缩快 45 倍。然而，相比 Choe 等人【2004】的方法，该方案的压缩开销约为 40%。

Yoon 和 Lindstrom【2007】的方法最近被扩展以支持几何随机访问，通过压缩由轴对齐包围体组成的包围体层次【Kim 等 2010】。在这个层次中，一个父包围体被分割成两个子包围体。压缩旨在保持生成层次的缓存一致性。生成了包含约 4,000 个包围体的包围体集群。这些集群被独立压缩以实现随机访问。每个叶子包围体的三角形顶点索引被编码，以实现对网格表面的几何随机访问。

##### 5.1.2. 层次随机访问压缩

Courbet 和 Hudelot【2009】提出了一种基于顶点序列的替代层次表示，也称为“线”。输入网格包含已编码的外部边界，被分割成两个平衡的部分。两个集群之间边界线的起始和结束顶点及其大小被编码，形成连接信息。线的几何形状使用与 Choe 等人【2009】相同的线性预测器进行编码。这两个部分然后以相同的方式递归地分割，直到每个部分只包含一个多边形。通过递归地分割线，直到遇到不可分割的多边形来解码一个元素。这种树结构允许只解压其中一个路径。因此，随机访问粒度很高（见图 13）。此外，多边形网格可以直接压缩。然而，与前两种方法相比，三角网格的压缩效率较低。平均成本为每个多边形 3 位连接性和每个顶点 14 位几何信息，使用 12 位量化。

#### 5.2. 渐进和随机访问压缩

##### 5.2.1. 基于连接性的算法

Kim 等人【2006】基于他们之前的网格细化框架【Kim 和 Lee 2001】提出了多分辨率随机访问网格压缩算法。在解压过程中，顶点可以被分割，即使其邻居与简化过程中的邻居不同。这打破了标准渐进网格表示【Hoppe 1996】的操作对称性。因此，在解压后的模型中，细化的区域可以与粗糙的区域相邻。通过对顶点分割层次结构的高效编码来压缩连接性和几何信息。这种方法提供了细粒度的多分辨率随机访问，但压缩性能有限（使用 12 位量化时约为 31 bpv）。

Cheng 等人【2007】描述了一种基于初始有意义分段的渐进随机访问网格压缩算法。通过沿着凹形特征轮廓切割网格来获得集群。网格的每个部分使用 Alliez 和 Desbrun【2001a】的渐进编码器的修改版本进行编码。插入顶点的位置使用极坐标和不同的量化方法进行编码。然而，算法没有考虑部分边界。同样，Maglo 等人【2011】将 Choe 等人【2009】的单率随机访问编码器扩展到渐进编码图表。图表边界顶点仍然独立编码，但提出了填补未完全解压图表之间空隙的方法。

POMAR 编码器【Maglo 等 2013】不需要输入模型的初始分段。离散的细节级别在压缩过程中通过半边折叠生成。粗糙的级别像渐进算法一样全局压缩。然而，对于细致的级别，通过分割顶点分割层次结构生成集群。通过对相邻集群施加最大细节级别差异为 1 的限制，该方案在粗糙和细致的解压区域之间生成平滑的过渡，并实现了高效的压缩性能（使用 12 位量化时为 15 bpv）。

##### 5.2.2. 几何基础算法

1. **Jamin et al. [2009] 和 Du et al. [2009] 的方法**
- **背景**：
     - 这两种算法在原有的Gandoin和Devilliers [2002] 渐进式算法基础上增加了随机访问支持。这些算法属于“出核”算法（out-of-core），即它们的处理不依赖于将整个模型加载到内存中（参见第3.3节）。
   
- **Jamin et al. [2009] 的CHuMI查看器**：
     - **nSP-tree**：Jamin等（2009）将网格的包围盒分割成一个层次结构，称为nSP-tree。这个结构由独立编码的SP-cells组成。属于多个SP-cell的顶点被复制，以便每个cell可以独立解码。
     - **kd-tree分解**：每个SP-cell都通过Gandoin和Devilliers [2002] 的kd-tree分解进行编码，编码连通性和几何信息。
     - **低量化处理**：为了解决低量化导致的块状效应，他们的方案预先编码了一些几何位。
   
- **Du et al. [2009] 的方法**：
     - **双层kd-tree**：Du等（2009）将原Gandoin和Devilliers [2002] 算法的kd-tree分解为两层。顶部树是第一层，而其子树集合为第二层。顶层树和每个子树被分别压缩，以实现随机访问。
     - **边界顶点解码**：在解码过程中，边界顶点可以与内部顶点独立解码。子树必须按预定义顺序压缩和解码，因为解码一个子树时，必须首先解码依赖列表中的前一个子树的边界顶点。

##### 5.2.3. 连通性无关的方案

- **重网格和小波变换**：
  - 对于渐进式和随机访问压缩算法，重网格（remeshing）提供了更高的自由度，从而实现更好的压缩率。这些方案通常基于半规则网格的小波分解框架，类似于它们的渐进式对应方法（参见第4.2.1节）。

- **Sim et al. [2005] 的方案**：
  - **法线网格表示**：Sim等（2005）使用了法线网格表示（Guskov等，2000）。在蝶形细分（butterfly subdivision）之后，将新边分配给簇（clusters）。该框架还包括一个失真模型、可见性测试方法和可见性优先级方法，用于视点依赖地解码模型。

- **Roudet [2010] 的方法**：
  - **波形分解**：Roudet（2010）使用输入半规则网格的小波分解的一个级别来将模型分割成同质系数大小的区域。每个区域随后被单独编码。

- **Gioia et al. [2004] 的框架**：
  - **动态添加和移除系数**：该框架允许动态地添加和移除小波系数，以细化或粗化模型，而无需解码整个分解。

- **小波方案的优点**：
  - 对于渐进式随机访问网格压缩，小波方案的关键优势是无需开发复杂的算法来随机访问原始连通性图。困难在于连通性必须被压缩成独立的簇。对于小波方案，只需确保一个簇的小波分解仅依赖于该簇的顶点即可。连通性由基础网格和细分方案设置，不需要为每个细节级别编码。

**总结**

- **几何基础算法**：Jamin et al. 和 Du et al. 的方法在传统的渐进式压缩算法上增加了随机访问支持，处理了细节级别和边界问题。Jamin et al. 采用了nSP-tree结构，而Du et al. 则通过双层kd-tree来实现随机访问。

- **连通性无关的方案**：这类方法通常利用小波分解框架，对半规则网格进行压缩。Sim et al. 和Roudet等的方法在模型编码和细化方面提供了新的策略，而Gioia等的框架允许在不解码整个模型的情况下动态修改细节。

这些算法和方法各有优劣，选择合适的方案取决于具体的应用需求，例如压缩效率、解码灵活性和实现复杂性。如果需要进一步探讨某个具体方法或有其他问题，请告诉我！

这段文字讨论了近年来提出的几种紧凑表示方法，这些方法在支持随机访问和常量时间遍历操作的同时，存储开销接近于压缩格式。以下是详细解释：

#### 5.3. 紧凑表示法

1. **SQuad 表示法**
- **背景**：
     - Gurung 等人（2011a）首次提出了SQuad表示法，用于三角网格的紧凑表示。
     
   - **原理**：
     - **四边形组合**：将三角形组合成四边形，并对四边形进行排序，使得第i个四边形与第i个顶点匹配。
     - **存储方式**：通过这种排序，只需要存储四边形角的一个表格，不需要显式存储顶点索引。顶点索引在运行时通过检查邻域中的小集合来推断。
     - **存储成本**：连接性存储成本大约为每个三角形两个整数引用。
   
- **扩展**：
     - **Luffel et al. (2014)**：扩展了SQuad表示法以支持即时流式构建和处理。这一扩展主要通过几何体和连接性的交错存储以及提高顶点和三角形之间的连贯性来实现。

2. **Laced Ring (LR) 表示法**
- **背景**：
     - Gurung 等人（2011b）提出了Laced Ring表示法，这是另一种紧凑数据结构。
     
   - **原理**：
     - **环路排序**：将顶点重新排序成一个接近哈密尔顿回路（称为环）。这种排序使得每个三角形只需要一个引用。
     - **存储成本**：每个三角形只需一个引用。
   
- **改进**：
     - **Zipper 方法**：Gurung 等人（2013）引入了改进的Zipper方法，能够将存储成本降低到每个三角形六位。这主要得益于顶点索引的差分编码和改进的环构造方法。

### **总结**

- **SQuad 表示法**：
  - **优点**：存储连接性信息所需的空间大约是每个三角形两个整数引用。通过在运行时推断顶点索引，实现了存储的紧凑性。
  - **扩展**：支持即时流式构建和处理，提高了顶点和三角形之间的连贯性。

- **Laced Ring 表示法**：
  - **优点**：每个三角形只需一个引用，进一步提高了存储的紧凑性。
  - **改进**：Zipper方法使得每个三角形的存储成本进一步降低到六位。

- **随机访问粒度**：
  - **定义**：表III中的“随机访问粒度”列（从1到5）定性地表示访问网格的特定部分时必须解压的元素数量。例如，低粒度表示访问某个顶点时需要解压较大区域。

这些紧凑表示法通过不同的策略减少了存储需求，同时保持了高效的访问和遍历性能。SQuad和Laced Ring分别在排序和引用管理上做出了创新，而Zipper方法在存储效率上进一步改进了LR表示法。如果需要进一步探讨某个具体方法或有其他问题，请告诉我！

这段文字介绍了在动态网格序列压缩领域的最新进展，并将现有方法分为几种不同的类别。以下是详细解释：

### **6. 动态网格序列压缩的现状**

随着基于相机的3D重建技术的进步，网格序列变得越来越普遍。由于这些序列通常包含短时间间隔，数据量非常庞大，因此需要高效的压缩方法，这与视频压缩类似，后者利用了连续图像之间的时间一致性。3D动画也是产生大量网格序列的一个领域。

目前，大多数科学界提出的技术仅针对具有恒定连通性的序列（即时间上连贯的网格序列）进行压缩（参见第2节）。对于具有可变连通性的序列（即时间上不连贯的网格序列），由于空间和时间上的冗余更难以利用，压缩问题的复杂性大大增加。根据目前的知识，只有Han et al. [2007]和Yamasaki和Aizawa [2010]处理了这个问题；他们借鉴了视频压缩技术，将网格分成块，然后对残差进行块匹配和编码。

### **动态网格压缩方法的分类**

动态网格压缩方法可以分为以下五类：

1. **带有先验分割的方法**：
   - **描述**：这些方法在压缩之前先对网格进行分割，以便于处理。例如，可能会根据网格的几何特征或其他标准将网格划分为不同的区域。

2. **基于PCA的方法**：
   - **描述**：主成分分析（PCA）用于对网格数据进行降维。通过提取网格的主要成分，可以有效地压缩数据。

3. **考虑时空预测的方法**：
   - **描述**：这些方法利用时空预测来压缩网格序列。例如，通过预测当前帧与前一帧之间的变化，可以减少需要存储的差异信息。

4. **小波方法**：
   - **描述**：利用小波变换来对网格进行多分辨率压缩。这些方法通过小波系数的不同尺度来表示网格数据，适合于处理具有不同细节层次的网格。

5. **MPEG算法**：
   - **描述**：利用类似于视频压缩的MPEG标准的方法来处理动态网格。这些算法采用标准化的编码技术以优化压缩效果。

### **动态网格压缩算法的关键特性**

1. **局部 vs 全局**：
   - **局部方法**：如Amjoun和Straßer [2009]所提，一些算法关注局部帧间变化，通常允许更快的（有时是实时的）压缩/解压缩。这些方法适用于需要快速处理的场景。
   - **全局方法**：另一类算法分析动态网格的全局一致性，以提高压缩性能。全局方法通常能够实现更高的压缩比，但可能需要更长的处理时间。

2. **可扩展性**：
   - **时空可扩展性**：动态网格包含大量数据，因此可扩展性非常重要。可扩展的压缩算法允许解码部分嵌入的比特流，以在降低帧率（时间上的可扩展性）或降低网格分辨率（空间上的可扩展性）下显示序列。可扩展的方法类似于静态网格的渐进方法，但在时间维度上也具有渐进性。
   - **局部和全局方法的应用**：局部和可扩展方法对低延迟流媒体尤其重要，特别是在手持设备上。全局和不可扩展的方法通常适用于下载后播放的场景。

这些分类和特性帮助理解动态网格序列压缩的现状以及各种方法的优缺点，从而可以根据具体需求选择最合适的压缩技术。如果你需要对某一类方法有更深入的了解或有其他问题，请告诉我！

这段文字讨论了动态网格序列压缩的现状，并对不同的压缩方法进行了详细描述。这些方法主要集中在如何有效地处理和压缩随时间变化的网格数据，以提高存储和传输效率。以下是每种方法的详细解释：

### **6.1. 基于先验分割的压缩方法**

一些作者提出了将动态网格的顶点划分为具有相似运动的点组的方法。例如：

- **Lengyel [1999]** 提出的最早的动态网格压缩算法，基于对顶点组进行刚性变换预测。将变换参数、分割信息以及预测误差编码以重建序列。
- **Gupta et al. [2002]** 通过对连续网格进行对齐来提高结果质量。
- **Sattler 和 Sarlette [2005]** 改进了基于顶点轨迹的分割方法，结合了Lloyd的聚类和PCA来对每个聚类进行压缩。
- **Mamou et al. [2006]** 考虑了几乎刚性分块，并用加权线性组合（皮肤模型）加上DCT压缩运动补偿误差。这种方法支持渐进传输（即空间可扩展性），通过对DCT系数排序实现。

### **6.2. 基于PCA的方法**

- **Alexa 和 Muller [2000]** 是首批将主成分分析（PCA）应用于动态网格压缩的作者。他们的思想是用通过SVD分解得到的主成分基来表示每一帧网格。通过传输少量的主成分基，可以实现高效压缩。
- **Karni 和 Gotsman [2004]** 改进了这个方法，将线性预测编码应用于PCA系数，引入了KG失真度量作为速率-失真评估的参考。
- **Sattler 和 Sarlette [2005]** 对空间聚类应用了PCA，**Luo et al. [2013]** 则对时间聚类应用了PCA。
- **Vasa 和 Skala** 提出了基于轨迹空间PCA的方法，其中包括预测PCA系数的机制、改进的预测器和优化的遍历顺序，显著提高了压缩效果。

### **6.3. 使用时空预测的方法**

- **Ibarria et al. [2003]** 提出了两种时空预测器：扩展的洛伦佐预测器（ELP）和REPLICA。ELP扩展了平行四边形规则，考虑了前一时间步的顶点位置预测。REPLICA使预测器对刚性变换（如旋转和缩放）具有鲁棒性。
- **Zhang 和 Owen [2007]** 以及 **Muller et al. [2006]** 将顶点位移向量放入层次树结构（八叉树），以利用时空一致性。
- **Amjoun 和 Straßer [2009]** 使用局部坐标系统编码增量向量。
- **Stefanoski 和 Liu [2007]** 将帧简化为空间层（即细节层次），利用相邻空间层和连续帧之间的空间和时间依赖性来估计顶点运动。
- **Stefanoski 和 Ostermann [2010]** 提出了可扩展预测编码（SPC），支持时空可扩展性，提供了优良的压缩比。
- **Ahn et al. [2013]** 改进了多层预测，获得了比SPC更好的性能。

### **6.4. 基于小波的方法**

一些作者提出了基于小波表示的算法：

- **Guskov 和 Khodakovsky [2004]** 使用小波分解将帧分解为层次，并对相邻帧之间的小波系数进行增量编码，实现空间可扩展性。
- **Payan 和 Antonini [2007]** 结合了时间小波滤波（时间可扩展性）和高效的比特分配过程。

### **6.5. MPEG框架**

2007年，**MPEG** 制定了动态网格压缩的标准，称为“帧基动画网格压缩”（MPEG-4 FAMC）：

- 结合了 **Mamou et al. [2006]** 的基于皮肤的方法和 **Stefanoski 和 Liu [2007]** 的可扩展方法。
- 提供了三种模式：可下载模式（无可扩展性）、可扩展模式（空间和时间可扩展）以及流媒体模式（将比特流分成不同的独立编码包）。
- 可下载模式提供了最佳的压缩率（2到7 bpfv）。

这段文字总结了动态网格序列压缩领域的主要方法和技术，包括基于先验分割、PCA、小波变换以及MPEG标准等各种策略。每种方法都有其特点和适用场景，选择合适的方法可以有效提高压缩效率和处理性能。

### **总结**

1. **早期网格压缩方法**
   - **单速率方法**：最初的网格压缩方法主要集中于连接性压缩。最早的方案包括基于三角形带（triangle strips）和顶点生成树（vertex spanning trees）的压缩。后来的方法通过压缩面生成树（face spanning trees）获得了更好的压缩率，但最终发现基于节点数（valence-driven）的方法在理论上提供了最优的压缩性能。
   - 随着研究的发展，社区开始关注几何预测和量化方法，因为几何数据的大小通常远大于连接数据的大小。

2. **渐进网格压缩方法**
   - **渐进方法**：在单速率方法之后，渐进网格压缩方法出现了。渐进方法包括小波方法、谱压缩等，这些方法提供了更好的率-失真性能。一些基于空间划分的几何驱动方法在低速率时可能会有较高的失真，但在重建算法方面表现优异。

3. **随机访问网格压缩**
   - 随着对大网格的压缩和访问需求增加，随机访问网格压缩方法逐渐出现。相对于单速率和渐进网格压缩，提出的随机访问方法较少。对于单速率随机访问网格压缩，提出了分段方法和层次方法。对于渐进随机访问网格压缩，小波方法在连接性可以修改的情况下表现出高的率-失真性能。此外，还有基于连接性保留的网格压缩方法。

4. **动态网格压缩**
   - **动态网格**：初期的动态网格压缩方法主要关注压缩率，使用全局方法。现在的趋势是考虑适合低延迟流式传输的局部可扩展方法。

### **未来发展方向**

1. **领域的演变**
   - 目前有三个独立的研究领域解决3D网格数据的存储和访问问题：
     - **纯压缩方法**：包括单速率和渐进算法，主要用于档案保存和传输。
     - **紧凑和/或可流式传输的数据结构**：如SQuad和LR表示，这些结构允许以更紧凑的方式进行网格遍历和常量时间访问。
     - **用于实时渲染的大规模数据集的层次数据结构**：这些结构优化了并行处理和渲染，但通常不涉及压缩。

   - 未来的挑战在于这些方法的融合。最近，一些紧凑的数据结构已经接近纯压缩方法的比特率，并支持数据的并行处理和流式外部访问。随机访问压缩方法可能会成为这三个研究领域的混合体。例如，Kim等人（2010）的随机访问渐进方法在压缩比、快速随机访问和快速渲染方面表现良好。

2. **未来的压缩方法应关注以下几点**：
   - **渲染优化**：未来的压缩方法需要关注渲染，因为渲染通常是内容传输的最终目标。例如，Karni等人（2002）提出的压缩机制优化了解压缩后的渲染序列。
   - **支持外部核心和并行处理**：现代计算架构越来越多核心，压缩方法需要适应这一趋势。例如，Meyer等人（2012）提出了一种基于广义三角形带的GPU网格压缩方案，通过并行扫描操作进行编码。
   - **适应上下文**：3D图形的使用正在向大众扩展，意味着需要适应不同的上下文和终端。例如，随着WebGL等技术的出现，嵌入3D网格的Web应用程序增加。压缩方法需要适应这种异质环境，可能会禁用复杂的预测和熵编码以减少复杂性和CPU使用。
   - **处理通用3D数据**：未来的压缩方法需要能够处理各种3D数据，包括不同的拓扑结构、表面或体积、带边界或不带边界的网格，以及各种属性（如纹理坐标、法线、颜色）。这将有助于标准化进程，例如MPEG和X3D社区已经开始的工作。

### **总结**

这段文字展示了网格压缩领域的历史发展、现状和未来方向。它强调了压缩技术从最初的单速率方法到渐进、随机访问和动态网格压缩的演变，并预测了未来在渲染优化、并行处理、上下文适应和通用数据处理方面的挑战和趋势。

这段文字讨论了在网格压缩算法设计和评估中引入感知度量的新范式。传统上，网格压缩算法的性能通常通过率-失真（rate-distortion）指标来比较，而失真常用的测量方法包括均方根误差（RMS）或Hausdorff距离。这些传统的几何测量方法并不总是能够准确地反映人类的视觉感知，因为最终的目标是将压缩后的模型展示给人类观察者，因此需要考虑视觉感知的质量作为评估标准。以下是详细解释：

### **感知度量的新范式**

1. **传统度量的局限性**
   - **均方根误差（RMS）和Hausdorff距离**：这些传统的几何测量方法用于衡量模型之间的差异，但它们并未考虑人眼对不同类型失真的敏感度。例如，人眼对法线的变化更为敏感，而不仅仅是位置的变化。

2. **感知度量的发展**
   - **L2,1度量**：Cohen-Steiner等人（2004）提出了基于法线的L2,1度量，这种度量考虑到人眼对法线变化的敏感性。
   - **网格视觉质量（MVQ）度量**：为了克服传统几何度量的不足，科学界近期引入了网格视觉质量度量。Corsini等人（2013）提出了这些度量，旨在预测失真3D数据相对于原始数据的视觉保真度。
   - **多尺度感知度量（MSDM2）**：Lavoue（2011）提出了基于均值曲率统计的多尺度感知度量。
   - **FMPD度量**：Wang等人（2012）设计了基于高斯曲率的拉普拉斯算子的FMPD度量。

3. **主观实验的结果**
   - **人类观察实验**：这些新的感知度量在主观实验中显示出比传统度量（如RMS或Hausdorff距离）更能捕捉到失真的视觉可见性。例如，Lavoue（2011）的研究表明，使用感知度量计算的渐进网格压缩算法的率-失真曲线与传统度量得出的结果不同。这意味着，全面的研究可能会显著改变目前对网格压缩算法的排名。

4. **未来的影响**
   - **新标准的建立**：感知度量作为3D视觉质量评估的新标准，类似于几年前图像和视频领域的情况。这些新的度量方法结合对3D场景可视化的感知机制的理解（如视觉对比度灵敏度函数），预计将对未来的3D网格压缩算法设计产生重大影响。

### **总结**

传统的网格压缩评估方法未能完全反映人眼对失真的感知。感知度量方法，如L2,1度量、多尺度感知度量和FMPD度量，提供了一种新的评估压缩算法的方式，这些度量能够更好地捕捉到视觉上明显的失真。未来的3D网格压缩算法设计将需要考虑这些感知度量，以提供更符合人类视觉感知的压缩效果。这种方法可能会改变当前的算法排名，并推动更符合实际视觉体验的压缩技术的发展。