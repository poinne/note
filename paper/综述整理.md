**整理**

- 根据模型区分
  - gan
  - stablediffusion
- 根据编辑区域区分
  - 对服装整体进行编辑修改（次要）
  - 对服装局部进行编辑修改（主要）
  - 对面部的属性进行修改（次要）
- 根据修改的内容
  - 形状轮廓
  - 纹理
  - 风格：（修改为指定的风格）
  - ...

- 根据引导条件的不同
  - 文本
  - 多模态条件
  - ...



将论文按照execl表格编号，然后用编号进行分类。





一、绪论：

XX话题背景介绍
XX话题的研究重要性及意义
XX话题的研究现状回顾
二、相关方法：

XX话题的一般方法介绍
XX话题的先进方法讨论
三、研究结果：

XX话题的实验结果分析
XX话题实验结果相关研究结论
四、展望：

XX话题的新技术展望
关于XX话题的未来研究发展方向

1.训练一个自编码器，实现输入包含目标掩码的图像和原始图像的轮廓图，输出重建后的原始图像。2.训练GAN模型，其中生成器的权重参数继承自第一步训练的自编码器的权重。实现输入包含目标掩码的图像和参考图像的轮廓图，生成修改对应目标属性后的图像。GAN的生成器在最后一层会额外多一个通道生成注意力图。3.生成器中添加VGG的感知损失来保证服装的整体纹理，生成器和判别器中添加属性感知损失来提高生成的质量。

1.通过LLM将输入的简单文本扩写，保证生成的风格。

2.GAN的隐空间划分层次，控制图像生成的重点（姿势，形状，纹理），保证人体姿态不变。

3.收集一个数据集，来指导生成模型对输入图像的潜在编码的修改。

4.使用GAN Inversion技术，在StyleGAN-Human模型基础上训练，通过StyleCLIP来修改GAN隐空间的编码









思路：先编辑目标属性对应区域的形状和边缘，然后通过图像修复网络填充该区域的像素，非目标区域通过mask图用原始图像代替。

具体过程分为三个阶段：

（1）训练形状编辑网络。将原始图像的语义分割图和轮廓图作为输入（轮廓图根据语义分割图生成），通过编码器编码后与目标属性编码进行拼接，然后送入预测器中进行预测，预测器有两个输出：具有目标属性的语义分割图，具有目标属性的轮廓图。作者使用了属性定位模块，用来定位目标属性的区域(相比于cam和attention map，属性定位模型可以更加清晰准确地定位目标区域的边缘)

 （2）训练像素填充网络(自编码器)，作用类似于deepfill，但是输入为语义分割图，目标属性区域掩码图，掩码与原始图像拼接图，修复后的图像更加符合语义要求。（3）推理阶段：首先通过形状编辑网络生成目标属性的语义分割图和掩码图，然后获得待修复区域的掩码，通过像素填充网络进行目标区域像素填充，非目标区域直接使用原始图像像素。（目标区域掩码获取方式如下：原始图像语义分割图x_a与属性定位模块得到的掩码图m逐像素点乘得到目标区域a，生成图像语义分割图x_b与属性定位模块得到的掩码图m逐像素点乘得到目标区域b，然后a与b求并集，得到待修复的区域掩码图）



UFS-Net:

将草图和待编辑服装分别嵌入到GAN隐空间中，然后通过生成器将两个潜在编码进行特征融合，生成图像。具体如下：模型分为两个部分：（1）嵌入过程（2）特征融合的生成过程。（1）嵌入过程 ， 分为两个部分。粗嵌入：训练一个编码器将草图和待编辑服装图片（或生成器通过噪音生成的图片）映射到W+空间中，然后通过损失函数来循环优化位于W+空间中的潜在编码。细嵌入：利用StyleGan的仿射变换将位于W+空间中的潜在代码转换到S空间中，然后通过损失函数循环优化位于S空间的新的潜在编码。最终可得到两个潜在编码：S_{sketch}、S_{cloth}。（2）特征融合的生成过程。 将两个潜在编码通过m进行加权求和，作为混合编码，送入生成器，但是S_{cloth}的低层隐含地携带着风格控制所必需的空间信息，因此，将潜在代码直接组合将导致生成的服装细节的丢失，因此将S_{mix}和S_{cloth}在每一层再次融合。论文的最后，作者将最终生成的图像与输入图像进行拼接，保证最终图像纹理一致。