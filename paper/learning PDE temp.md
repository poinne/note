1. 
2. 如何将learning与sdf联系起来？
3. 如何用learning计算sdf?
4. 这些论文是在欧式空间计算的，我需要在流形空间计算



**Deep Eikonal Solvers：**

Eikonal 方程用于描述在给定空间中从源点到其他点的最短路径的性质，特别是在计算测地距离时。

快速 Eikonal 求解器（Fast Eikonal Solvers）是一类用于高效计算 Eikonal 方程解的方法，主要应用于计算距离场和最短路径问题。

**快速行进法**是最著名的快速Eikonal求解器之一：

Fast marching method：

可以计算每个网格顶点相对于某个**源点（或初始曲线）**的距离函数值（测地距离）。

快速Eikonal求解器主要包括两个部分：

- **局部数值求解器**：用于在某个点近似计算距离函数。它根据该点周围的已知距离值，提供该点的距离近似值。
- **排序/更新方法**：决定下一个要计算的点。这个方法会选择合适的点来进一步近似距离函数。



论文的目的就是训练一个模型作为局部数值求解器，传统的局部数值求解器是通过公式和数学推导计算点的距离近似，而新的方法则使用**神经网络**来代替公式。

神经网络经过训练后，能够对不同的几何结构和采样条件下的局部距离进行更高精度的估计。





**DGM: A deep learning algorithm for solving partial differential equations**

DGM算法的核心思想是通过神经网络近似求解高维偏微分方程。

使用神经网络近似偏微分方程中的函数，

具体做法是使用随机梯度下降（SGD）方法在没有构造grid的情况下逼近PDE的解。这个方法的关键步骤是随机生成空间和时间点，在这些点上计算误差并通过梯度下降更新神经网络的参数。

神经网络可以看做对某个函数的近似，我们使用神经网络来近似偏微分方程的解，并根据该近似的解与原方程的匹配程度定义[损失函数](https://zhida.zhihu.com/search?content_id=170428981&content_type=Article&match_order=1&q=损失函数&zhida_source=entity)，通过训练神经网络，优化损失函数，我们求得神经网络的参数，神经网络所表达的函数得以确定后，我们就得到了原方程的近似解。在DGM的方法中，损失函数采用的是基于强解（Strong Solution）的构造，即假定求得的解满足原方程所要求的光滑性质。

使用神经网格近似抛物线偏微分方程：

![image-20241002200646818](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241002200646818.png)

![image-20241002200742345](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241003104138176.png)

![image-20241002200757196](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241002200742345.png)

![image-20241003104120734](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241003104159248.png)

![image-20241003104138176](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241002200757196.png)

![image-20241003104159248](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241002204652083.png)





:

这篇文章使用深度神经网络来得到偏微分方程的数值解，应该是一种强解，主要思想就是用神经网络来拟合偏微分方程的解函数。文章后面也使用了二阶的方法来加速求解。

但是训练好后只能拟合一个偏微分方程的解



**Weak Adversarial Networks for High-dimensional Partial Differential Equations**

利用GAN的思想求偏微分方程的弱解。

在没有强解的情况下，WAN方法能对弱解有更好的近似，而基于强解的方法有更大的误差。而当原方程有强解的时候，所有的方法效果相差不大。





![image-20241002204652083](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241003140508088.png)



在对于线性偏微分方程，通常可以使用更直接的方法来求解，比如：

1. **分离变量法**：将偏微分方程分解为几个单变量的方程，进而求解。
2. **特征线法**：用于一阶偏微分方程，通过构造特征线来简化问题。
3. **傅里叶变换或拉普拉斯变换**：对于特定边界条件的线性偏微分方程，可以通过变换方法求解。
4. **有限差分法或有限元法**：这些数值方法也适用于线性偏微分方程，通常比牛顿法更为高效。

尽管牛顿法可以用于线性偏微分方程，尤其是在将其转化为线性代数方程组时，但由于其特性和要求的计算量，使用专门针对线性问题的方法会更为方便和高效。因此，牛顿法在处理线性偏微分方程时并不常用。

牛顿法可以用于求解偏微分方程（PDEs），尤其是在涉及到非线性偏微分方程的情况下。牛顿法主要是用来寻找方程的根，而许多偏微分方程可以通过将其转化为一个非线性方程的形式来应用牛顿法。

在具体应用中，牛顿法通常结合有限差分法、有限元法或谱方法等数值方法，以离散化偏微分方程。这种方法的基本思路是：

1. **离散化**：使用适当的数值方法将偏微分方程转化为离散形式，通常得到一个非线性代数方程组。
2. **构造雅可比矩阵**：对非线性方程组求解时，需要计算雅可比矩阵，该矩阵包含了方程组关于未知数的偏导数。
3. **迭代求解**：通过牛顿迭代公式，不断更新未知数的值，直到收敛到所需的精度。

牛顿法的优点在于其收敛速度快，尤其是在接近解时。然而，它也有一些缺点，比如对初始猜测的敏感性以及在高维情况下计算雅可比矩阵的开销较大。

总的来说，牛顿法在求解某些类型的偏微分方程时是有效的，尤其是在处理非线性问题时。

![image-20241003140508088](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241010101700805.png)





**截断误差**



由实际问题建立起来的数学模型，在很多情况下要得到准确解是困难的，通常要用数值方法求它的近似解，例如常把无限的计算过程用有限的计算过程代替，这种模型的准确解和由数值方法求出的近似解之间的误差称为截断误差。因为截断误差是数值计算方法固有的，因此又称方法误差。





##### PHYSICS-AWARE DIFFERENCE GRAPH NETWORKS FOR SPARSELY-OBSERVED DYNAMICS

该论文虽然是用learning方式解定义在mesh上的动态的PDE，但是用的还是数据驱动的方式。

论文是这样做的：

1. **作者图网络（GN）以及有限差分，定义了一个模块：**

   **通过将传统离散微分几何中对梯度和拉普拉斯的定义的修改，将权改为可学习的权重，定义了在网络中求梯度和拉普拉斯的方法。**

   【提出空间差异层（SDL），由一组可学习的参数组成，用于定义可学习的差分算子作为梯度和拉普拉斯算子的一种形式，以充分利用邻近信息。】（论文翻译）

   1. 传统的方法：

      ![image-20241010101451480](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241010101519598.png)

      ![image-20241010101519598](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241003104120734.png)

      定义在三角网格上的微分算子：

      ![image-20241010101700805](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241010101810590.png)

      

      作者修改后的定义：

      ![image-20241010101726379](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241010101451480.png)

      

      可学习的权重通过GN的k-hop子图得到：

      相当于高阶差分方程。

      ![image-20241010101810590](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241010101726379.png)

      （虽然权重使用可k-hop子图，但是在进行差分时还是用的一邻域？）

   ​	在得到mesh上各顶点的信号的梯度和拉普拉斯后，将它们与当前信号$f(t)$进行连接，得到差分图（different graph)(有限差分形成的图),差分图包括描述空间变化的所有信息。

   此时，每个节点的特征包括（定义在节点上的信号值，经过调制的梯度，经过调制的拉普拉斯）

   **虽然得到了差分图（包括梯度和拉普拉斯和信号值），但是作者并没有直接用差分图进行信号值的更新和计算，而是将它作为一个特征向量，输入进RGN中，进行信号值的更新。**

   所以作者设计这个模块，求图上顶点和边的梯度和拉普拉斯的目的并不是为了进行PDE的计算，而是将之作为一种特征来指导网络参数的更新。= =

2. 将第一步得到的差分图输入进RGN中（这里的GRN可以是任意的循环图网络），进行信号值的更新。



**训练过程：**

对于要求解的动态PDE，根据在连续背景下的公式，结合有限差分，得到其对应的离散情况下的PDE公式，然后采样得到数据集。

数据集中数据为$(x,y),t_i,f(t_i)$，即对于每个空间中的采样点(x,y)，都有一系列的时间步长的时间和对应时间下的信号值。

训练过程为有监督训练，损失函数为预测值与真值的MSE。



##### Mesh PDE

1. 如何在网络中定义mesh上的信号场？

2. 如何求解、更新信号场？

   通过循环图网络进行更新