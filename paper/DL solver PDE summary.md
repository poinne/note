#### DL solver PDE summary





已知PDE方程以及一些观测数据后，可以使用PINN

未知PDE方程，但是有大量的观测数据，可以使用DeepONet（learning Operator),但是需要高质量训练数据的依赖和计算密集度高



##### FINNs

[[博客](https://zhuanlan.zhihu.com/p/411843646)]

FINNs全称为 （Physics-informed neural networks），与传统的数据驱动的神经网络不同，PINNs 在学习过程中利用物理法则对模型进行指导，从而提高模型泛化能力，特别是在数据较少或噪声较大的情况下。

PINNs 通过训练神经网络来最小化一个损失函数，从而生成 PDE 的近似解。

PINN可以通过少量的数据进行PDE的求解，具体地，可以只通过初值和边界值以及PDE方程进行学习和求解。

为了实现只有初边值条件和方程即可约束神经网络，需要在损失函数上花心思，毕竟损失函数决定了神经网络训练的方向。PINNs的损失函数分为两块，一块是初始条件和边界条件，一块是方程。

- 表示空间-时间域边界上初始条件和边界条件偏差的项，

  使用初值和边界条件做约束条件比较简单，直接做一个MSE即可。

- 表示域内选定点上 PDE 残差的项。

  这部分是PINN的关键，即偏微分方程的残差，当输出的u和对应的导数满足方程时，f是等于0的。因此目标是让f尽可能的接近0。这样就实现了即使不知道真值u，也能计算出方程的Loss用于指导神经网络参数的更新，实现了非监督学习的效果。

通过最小化这些偏差，神经网络能够逼近 PDE 的解。

PINNs 的优势在于其灵活性，因为它们可以应用于各种具有挑战性的偏微分方程，而经典数值近似通常需要根据特定偏微分方程的具体情况进行定制。

损失函数中PDE残差的项需要对t进行求导，以及计算一些偏微分算子，这些都可以通过pytorch库提供的自动微分得到。

举例如下：

对于偏微分方程：

![image-20241012150835037](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241012150835037.png)

可以构造对应的损失函数：

![image-20241012150858220](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241012150858220.png)

因为PDE本身就是0，因此只需要最小化PDE的值的平方即可，而初始和边界条件则需要最小化其与gt值之差的平方。

**PINN训练过程**

PINN 训练时，输入的数据主要分为两类：

1. **边界条件和初始条件的数据**：
   - PINN的一个关键特点是，它可以处理具有**小数据**的PDE问题。因此，网络的训练数据通常是偏微分方程的**边界条件**和**初始条件**.
   - 这部分的数据属于有监督训练，即对于每个预测的值，都会提供对应的真值用于loss计算。
   - 这部分的数据，训练时初边值的loss和PDE残差的loss都会计算。

2. **内部点的采样数据**：
   - 为了使神经网络逼近PDE的解，PINN在**空间-时间域的内部**随机选择一些点。在这些点上，网络通过自动微分来计算PDE的残差（例如偏导数），并将PDE的残差引入到损失函数中进行优化。
   - 这些内部点并不需要提供确切的解值，而是通过自动微分评估解是否符合PDE的要求。因此，PINN能够在缺乏大量训练数据的情况下通过物理约束来指导网络的训练。
   - 这部分的数据属于无监督训练，即对于每个预测的值，没有对应的真值用于loss计算。
   - 这部分的数据，训练时只会计算PDE残差的loss。

PINN的输入特征：

- **时空坐标点**：即 \( (t, x) \) 的值，这些点可以是时间和空间域内的任意位置。
- **边界条件和初始条件**：这些条件会提供在特定时刻和特定空间边界处的已知解，作为训练的监督数据。

PINN 的训练过程主要是通过将输入的时空坐标和边界/初始条件结合在一起，并通过最小化损失函数（包含PDE残差、边界条件、初始条件的偏差）来优化神经网络的参数。



PINN模型也有许多明显的不足：

- 由于模型内部缺乏偏微分方程信息，PINN 模型的预测可能不符合物理原理。因此，这些方法不适用于构建可概括形状和边界条件变化的模型。（即模型的泛化能力很差)

