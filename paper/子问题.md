##### 根据训练策略分类：

1. 基于训练的方法（四种）

   - 具有弱监督的领域特定编辑

   - 通过自监督进行参考和属性引导

     - 基于参考的图像合成

     - 属性控制的图像编辑

       这类论文通常涉及以特定的图像特征作为控制条件来增强预训练的扩散模型，以学习相应图像的生成。这种方法可以通过改变这些特定的控制条件来实现图像编辑。

   - 通过完全监督进行指导性编辑

   - 使用弱监督进行伪目标检索

2. 测试时微调的方法

3. 自由训练于微调的方法

##### 根据编辑任务分类：

1. 语义编辑：
   - 对象添加（Obj. Add.）
   - 对象移除（Obj. Remo.）
   - 对象替换（Obj. Repl.）
   - 背景更改（Bg. Chg.）
   - 情感表达修改（Emo. Expr. Mod.）
2. 风格编辑：
   - 颜色更改（Color Chg.）
   - 纹理更改（Text. Chg.）
   - 整体风格更改（Style Chg.）
3. 结构编辑：
   - 对象移动（Obj. Move.）
   - 对象大小和形状更改（Obj. Size. Chg.）
   - 对象动作和姿态更改（Obj. Act. Chg.）
   - 透视/视角更改（Persp./View. Chg.）



### 子问题

- 提高生成图像（区域）的质量

- 保持无关区域不变

  - objectStitch：设计了一个Content Adaptor保留参考图的关键信息

  - Anydoor：引入了捕获身份特征、保留纹理和学习外观变化的模块
  - Smart Brush使用不同粒度的掩膜作为控制条件，根据掩膜的文本和像拽修复掩膜区域。
  - 使用clip损失



### 具体方法：

- DiffusionCLIP：利用冻结的预训练DDIM完成加噪，使用不冻结的预训练DDIM模型副本进行去噪。并通过CLIP损失更新预训练副本的参数。
- EGSDE：使用一个能量函数来指导采样，以实现真是的非成对图像到图像的转换。改函数由两个对数势函数组成。分别由一个依赖于时间的特定域分类器和一个低通滤波器指定。
- InstructPix2Pix：使用指令进行图像编辑（1.生成成对的图像和对应的指令。2. 使用全监督的方式训练一个模型，以图像和指令语句作为输入）
- MoEController: 包括三部分：用于细粒度的局部翻译、全局风格迁移和复杂的局部编辑任务
- Inst-Inpaint：用户通过简单的文本命令将指定要从图像中移除的对象。而不需要二进制掩码。
- HIVE：在指导图像编辑中引入了人类反馈的强化学习，在得到基础模型后，在人类排序数据集上训练奖励模型。将奖励模型的估计融入到训练过程中，对扩散模型进行微调，使其与人类反馈保持一致。
- ImageBrush：出从一对变换图像中学习视觉指令，说明所需的操作，并应用该指令编辑新图像。该方法将示例图像、源图像和空白图像拼接成一个网格，利用扩散模型根据示例图像提供的上下文信息对空白图像进行迭代去噪。此外，还提出了一种视觉提示编码器，用于从视觉指令中提取特征，以增强扩散过程。
- iEdit：利用CLIP检索出个编辑文本最相近的图像作为伪目标图像指导生成。此外，它通过 CLIPSeg 还将掩码纳入图像编辑过程中，以实现局部保留。
- TDIELR：具有定位和检索的文本引导的区域图像编辑。首先通过图像定位（DINO）对输入图像进行处理，生成注意力图和特征用于区域初始化。用于指定要编辑的区域。通过区域生成网络（RGN），从后选区域中选择最适合的区域。然后通过预训练模型进行图像编辑。通过ClIP计算分数，训练EGN。
- 