#### 论文1：Current and emerging deep-learning methods for the simulation of fluid dynamics

这篇文章总结了当前利用深度学习（DL）解决流体动力学的问题，主要看了对物理驱动的方法，对于数据驱动的方法，涉及到很多流体动力学的问题，没有看。



文章将DL解PDE分为物理驱动方法和数据驱动方法。

分类的标准是是否学会满足控制方程或使用方程的解的结果。

- 物理驱动的方法通常会调整深度学习模型，通过最小化控制偏微分方程的残差，为给定的流体动力学问题提供解析和可微分的解决方案。
  - 以无监督的方式训练，以获得最小化控制方程残差的解决方案。
  - 可以学习流体动力学单个实例的准确解。
- 数据驱动方法为任何流体动力学问题提供了快速、近似的解决方案，这些问题与调整深度学习模型参数时使用的观察结果共享一些物理属性。
  - 数据驱动的方法主要是最小化预测值和实际值之间的差异。
  - 速度更快，泛化性更好，但是准确性不确定。

##### Physics-driven neural flow solvers

**修改的 method of weighted residuals (MWR)**

加权残差法（Method of Weighted Residuals, MWR）是一种用于求解偏微分方程（PDE）的数值方法。该方法的基本思想是将PDE的解表示为某种形式的试探函数，并通过引入加权函数，最小化方程在某种意义上的残差。

具体步骤如下：

1. **选择试探函数**：假设解可以用一组已知函数（试探函数）表示。

2. **定义残差**：计算将试探函数代入PDE后产生的残差，即原方程和试探解之间的差异。

3. **引入加权函数**：选择一组加权函数，这些函数通常与试探函数相关。

4. **形成弱形式**：通过将残差与加权函数相乘并在定义域内积分，得到一个方程组，这样可以“加权”不同区域的误差。

5. **求解方程**：通过调整试探函数的系数，使得加权残差为零，从而得到近似解。

将DL与MWR结合，通过MLP来代替试探函数

这个相关的论文都很老了。



物理驱动网络之间的主要区别体现在以下几个方面：

1. **初始和边界条件的施加方式**：有些网络采用“弱约束”（weak constraints），即通过最小化残差的方式来处理初始和边界条件；而另一些网络则使用“硬约束”（hard constraints），直接将条件强加于网络。
2. **残差的聚合方式**：网络计算偏微分方程（PDE）在每个采样点的残差时，可以选择直接求和（direct sum）或者对空间和/或时间进行积分。这种选择会影响网络的训练方式和最终解的质量。

**physics-informed neural networks (PINNs)**

PINNS可用于解决PDE的正向和逆向问题。

**正向问题**就是求解PDE，将PDE残差和初边值误差作为损失函数。

![image-20241021164104163](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241021164104163.png)

这种方法和早期的物理驱动的神经求解器类似，但是采样点是任意的，而不是通过网格划分算法生成的，属于meshfree的方法。



**逆问题**是指系统的偏微分方程（PDEs）中有一个或多个参数未知，而目标是通过已知的部分数据来推测这些未知参数的近似值。在流体力学中，PINN被用于参数识别（如确定未知的物理参数）和场重建（通过分散的实验测量数据重建流体的物理场）。这让PINN在处理不完全数据或实验数据重建方面非常有用。



当前物理驱动求解器的最大问题是收敛速度通常比数值求解器慢，并且PDE的残差仍然比较高。目前也有一些解决方法。



##### Data-driven neural solvers

通过数值求解器得到模型训练的数据集，包括变量和对应的观测值，用于模型的监督训练。以最小化损失函数，该损失函数量化网络的预测与这些量的地面实况观察之间的误差。经过训练后，神经网络模型就构成了一个插值器，能够在给定输入变量的情况下逼近解。

这种模型的推导速度很快（相比于数值求解器，快2到4个数量级）

**数值求解器的迭代特性**：隐式数值求解器需要通过反复迭代来解决大规模的方程组，每次迭代都需要耗费大量的计算资源。而神经网络通过训练后，只需要一次前向传播（一次评估）就能返回一个解，避免了迭代的过程。这使得神经网络推理速度显著更快。

**网格与时间步长的灵活性**：显式数值求解器通常需要严格的**稳定性约束**，比如网格尺寸和时间步长必须足够小，才能保证数值解的准确性和稳定性。这种约束导致数值求解器的计算成本很高。而神经网络在求解过程中没有这些严格的约束，允许使用更粗的网格和时间离散化，从而进一步减少计算量。

但是插值性质限制了模型的泛化性能。很多研究目的都是为了减轻这种限制，并将物理知识嵌入到模型中。综述中讨论了四类：



通常使用的模型为CNN、U-net、GNN、RNN。

这种方法推理的速度很快，但是准确性不能保证，且泛化能力不强。虽然推理的速度很快，但是模型训练数据的生成成本较高（需要数值求解器生成大量配对数据）

因此这种方法通常是针对特定的目标应用程序进行涉及和训练的。

**CNN架构**

CNN适合与几何与坐标系对其的模拟

**GNN架构**

GNN适合复杂的几何模拟和拉格朗日系统。



多尺度CNN、GNN是什么



数据驱动部分主要讨论了几种解决流体PDE的方法

###### Data-driven flow inference on structured meshes



#### 论文2：Solving partial differential equations using large‐data models: a literature review

`Artificial Intelligence Review 2024`

##### 不同模型求解PDE

###### CNN

文中并没有说明是怎么做的，只是说结构对问题的适应性较差。

###### PINN



###### DeepONet CNN

DeepONet【待看】【】

![image-20241021212131377](https://raw.githubusercontent.com/poinne/md-pic/main/image-20241021212131377.png)

###### RNN

PhyCRNet：结合CNN和LSTM求解PDE 【待看】【】



###### LSTM

【待看（）】



###### GAN

WGAN solver PDE【待看】【】



###### Transformers

Choose a transformer: Fourier or Galerkin

###### DRLNNs

通过强化学习来求解PDE，看看怎么做的，效果如何，可不可以用【】



##### 当前趋势











